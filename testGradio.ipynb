{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff478eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<bound method Blocks.close of Gradio Interface for: greet\n",
       "---------------------------\n",
       "inputs:\n",
       "|-<gradio.components.textbox.Textbox object at 0x000002204A6A7E60>\n",
       "|-<gradio.components.slider.Slider object at 0x000002204A6531D0>\n",
       "outputs:\n",
       "|-<gradio.components.textbox.Textbox object at 0x000002204A6A4410>>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def greet(name, intensity):\n",
    "    return \"Hello, \" + name + \"!\" * int(intensity)\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=greet,\n",
    "    inputs=[\"text\", \"slider\"],\n",
    "    outputs=[\"text\"],\n",
    ")\n",
    "\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b69ac18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using actual classes for inputs and outputs\n",
    "import gradio as gr\n",
    "\n",
    "def greet(name, intensity):\n",
    "    return \"Hello, \" + name + \"!\" * intensity\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=greet,\n",
    "    inputs=[\"text\", gr.Slider(value=2, minimum=1, maximum=10, step=1)],\n",
    "    outputs=[gr.Textbox(label=\"greeting\", lines=3)],\n",
    ")\n",
    "\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0d4449d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7864\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7864/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def greet(name, is_morning, temperature):\n",
    "    salutation = \"Good morning\" if is_morning else \"Good evening\"\n",
    "    greeting = f\"{salutation} {name}. It is {temperature} degrees today\"\n",
    "    celsius = (temperature - 32) * 5 / 9\n",
    "    return greeting, round(celsius, 2)\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=greet,\n",
    "    inputs=[\"text\", \"checkbox\", gr.Slider(0, 100)],\n",
    "    outputs=[\"text\", \"number\"],\n",
    ")\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd0a466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7875\n",
      "Caching examples at: 'd:\\Users\\Carlos\\Documents\\Code\\AI_media\\.gradio\\cached_examples\\326'\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7875/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# image example\n",
    "import numpy as np\n",
    "import gradio as gr\n",
    "\n",
    "def sepia(input_img):\n",
    "    sepia_filter = np.array([\n",
    "        [0.393, 0.769, 0.189],\n",
    "        [0.349, 0.686, 0.168],\n",
    "        [0.272, 0.534, 0.131]\n",
    "    ])\n",
    "    sepia_img = input_img.dot(sepia_filter.T)\n",
    "    sepia_img /= sepia_img.max()\n",
    "    return sepia_img\n",
    "\n",
    "demo = gr.Interface(\n",
    "    sepia, \n",
    "    gr.Image(), \n",
    "    \"image\", \n",
    "    title=\"SepiaMaker\", \n",
    "    description=\"Converts an image to sepia tone\", \n",
    "    article=\"here are some additional details\",\n",
    "    examples=\"sampleImages\",\n",
    "    # cache_examples=True,\n",
    ")\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9949cbdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\Carlos\\Documents\\Code\\AI_media\\env\\Lib\\site-packages\\gradio\\interface.py:415: UserWarning: The `allow_flagging` parameter in `Interface` is deprecated.Use `flagging_mode` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7876\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7876/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with examples\n",
    "import gradio as gr\n",
    "\n",
    "def calculator(num1, operation, num2):\n",
    "    if operation == \"add\":\n",
    "        return num1 + num2\n",
    "    elif operation == \"subtract\":\n",
    "        return num1 - num2\n",
    "    elif operation == \"multiply\":\n",
    "        return num1 * num2\n",
    "    elif operation == \"divide\":\n",
    "        if num2 == 0:\n",
    "            raise gr.Error(\"Cannot divide by zero!\")\n",
    "        return num1 / num2\n",
    "\n",
    "demo = gr.Interface(\n",
    "    calculator,\n",
    "    [\n",
    "        \"number\",\n",
    "        gr.Radio([\"add\", \"subtract\", \"multiply\", \"divide\"]),\n",
    "        \"number\"\n",
    "    ],\n",
    "    \"number\",\n",
    "    examples=[\n",
    "        [45, \"add\", 3],\n",
    "        [3.14, \"divide\", 2],\n",
    "        [144, \"multiply\", 2.5],\n",
    "        [0, \"subtract\", 1.2],\n",
    "    ],\n",
    "    title=\"Toy Calculator\",\n",
    "    description=\"Here's a sample toy calculator.\",\n",
    "    # allow_flagging=\"never\"\n",
    ")\n",
    "\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe70af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7869\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7869/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#additional inputs example\n",
    "import gradio as gr\n",
    "\n",
    "def generate_fake_image(prompt, seed, initial_image=None):\n",
    "    return f\"Used seed: {seed}\", \"https://dummyimage.com/300/09f.png\"\n",
    "\n",
    "demo = gr.Interface(\n",
    "    generate_fake_image,\n",
    "    inputs=[\"textbox\"],\n",
    "    outputs=[\"textbox\", \"image\"],\n",
    "    additional_inputs=[\n",
    "        gr.Slider(0, 1000),\n",
    "        \"image\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "demo.launch()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9745bfcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7877\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7877/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# global state example\n",
    "import gradio as gr\n",
    "\n",
    "scores = []\n",
    "\n",
    "def track_score(score):\n",
    "    scores.append(score)\n",
    "    top_scores = sorted(scores, reverse=True)[:3]\n",
    "    return top_scores\n",
    "\n",
    "demo = gr.Interface(\n",
    "    track_score,\n",
    "    gr.Number(label=\"Score\"),\n",
    "    gr.JSON(label=\"Top Scores\")\n",
    ")\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "252039a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7878\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7878/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# session state example\n",
    "import gradio as gr\n",
    "\n",
    "def store_message(message: str, history: list[str]):  \n",
    "    output = {\n",
    "        \"Current messages\": message,\n",
    "        \"Previous messages\": history[::-1]\n",
    "    }\n",
    "    history.append(message)\n",
    "    return output, history\n",
    "\n",
    "demo = gr.Interface(fn=store_message,\n",
    "                    inputs=[\"textbox\", gr.State(value=[])],\n",
    "                    outputs=[\"json\", gr.State()])\n",
    "\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ae49bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7879\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7879/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#live interface example --no submit button\n",
    "import gradio as gr\n",
    "\n",
    "def calculator(num1, operation, num2):\n",
    "    if operation == \"add\":\n",
    "        return num1 + num2\n",
    "    elif operation == \"subtract\":\n",
    "        return num1 - num2\n",
    "    elif operation == \"multiply\":\n",
    "        return num1 * num2\n",
    "    elif operation == \"divide\":\n",
    "        return num1 / num2\n",
    "\n",
    "demo = gr.Interface(\n",
    "    calculator,\n",
    "    [\n",
    "        \"number\",\n",
    "        gr.Radio([\"add\", \"subtract\", \"multiply\", \"divide\"]),\n",
    "        \"number\"\n",
    "    ],\n",
    "    \"number\",\n",
    "    live=True,\n",
    ")\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "898cc012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7880\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7880/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#streaming images example\n",
    "import gradio as gr\n",
    "import numpy as np\n",
    "\n",
    "def flip(im):\n",
    "    return np.flipud(im)\n",
    "\n",
    "demo = gr.Interface(\n",
    "    flip,\n",
    "    gr.Image(sources=[\"webcam\"], streaming=True),\n",
    "    \"image\",\n",
    "    live=True\n",
    ")\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd8bc9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\Carlos\\Documents\\Code\\AI_media\\env\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\cfune\\.cache\\huggingface\\hub\\models--openai--whisper-base.en. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Device set to use cuda:0\n",
      "d:\\Users\\Carlos\\Documents\\Code\\AI_media\\env\\Lib\\site-packages\\torch\\cuda\\__init__.py:209: UserWarning: \n",
      "NVIDIA GeForce RTX 5060 Ti with CUDA capability sm_120 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_61 sm_70 sm_75 sm_80 sm_86 sm_90 compute_37.\n",
      "If you want to use the NVIDIA GeForce RTX 5060 Ti GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7881\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7881/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\Carlos\\Documents\\Code\\AI_media\\env\\Lib\\site-packages\\transformers\\models\\whisper\\generation_whisper.py:512: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "d:\\Users\\Carlos\\Documents\\Code\\AI_media\\env\\Lib\\site-packages\\transformers\\models\\whisper\\modeling_whisper.py:545: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    }
   ],
   "source": [
    "# ASR test\n",
    "# https://www.gradio.app/guides/real-time-speech-recognition\n",
    "import gradio as gr\n",
    "from transformers import pipeline\n",
    "import numpy as np\n",
    "\n",
    "transcriber = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-base.en\")\n",
    "\n",
    "def transcribe(audio):\n",
    "    sr, y = audio\n",
    "    \n",
    "    # Convert to mono if stereo\n",
    "    if y.ndim > 1:\n",
    "        y = y.mean(axis=1)\n",
    "        \n",
    "    y = y.astype(np.float32)\n",
    "    y /= np.max(np.abs(y))\n",
    "\n",
    "    return transcriber({\"sampling_rate\": sr, \"raw\": y})[\"text\"]  \n",
    "\n",
    "demo = gr.Interface(\n",
    "    transcribe,\n",
    "    gr.Audio(sources=\"microphone\"),\n",
    "    \"text\",\n",
    ")\n",
    "\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1de3c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7882\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7882/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\Carlos\\Documents\\Code\\AI_media\\env\\Lib\\site-packages\\transformers\\models\\whisper\\generation_whisper.py:512: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Users\\Carlos\\Documents\\Code\\AI_media\\env\\Lib\\site-packages\\gradio\\queueing.py\", line 625, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Users\\Carlos\\Documents\\Code\\AI_media\\env\\Lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Users\\Carlos\\Documents\\Code\\AI_media\\env\\Lib\\site-packages\\gradio\\blocks.py\", line 2143, in process_api\n",
      "    inputs = await self.preprocess_data(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Users\\Carlos\\Documents\\Code\\AI_media\\env\\Lib\\site-packages\\gradio\\blocks.py\", line 1816, in preprocess_data\n",
      "    processed_input.append(block.preprocess(inputs_cached))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Users\\Carlos\\Documents\\Code\\AI_media\\env\\Lib\\site-packages\\gradio\\components\\audio.py\", line 264, in preprocess\n",
      "    return processing_utils.audio_from_file(payload.path)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Users\\Carlos\\Documents\\Code\\AI_media\\env\\Lib\\site-packages\\gradio\\processing_utils.py\", line 701, in audio_from_file\n",
      "    audio = AudioSegment.from_file(filename)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Users\\Carlos\\Documents\\Code\\AI_media\\env\\Lib\\site-packages\\pydub\\audio_segment.py\", line 773, in from_file\n",
      "    raise CouldntDecodeError(\n",
      "pydub.exceptions.CouldntDecodeError: Decoding failed. ffmpeg returned error code: 3199971767\n",
      "\n",
      "Output from ffmpeg/avlib:\n",
      "\n",
      "ffmpeg version 7.0-essentials_build-www.gyan.dev Copyright (c) 2000-2024 the FFmpeg developers\n",
      "  built with gcc 13.2.0 (Rev5, Built by MSYS2 project)\n",
      "  configuration: --enable-gpl --enable-version3 --enable-static --disable-w32threads --disable-autodetect --enable-fontconfig --enable-iconv --enable-gnutls --enable-libxml2 --enable-gmp --enable-bzlib --enable-lzma --enable-zlib --enable-libsrt --enable-libssh --enable-libzmq --enable-avisynth --enable-sdl2 --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxvid --enable-libaom --enable-libopenjpeg --enable-libvpx --enable-mediafoundation --enable-libass --enable-libfreetype --enable-libfribidi --enable-libharfbuzz --enable-libvidstab --enable-libvmaf --enable-libzimg --enable-amf --enable-cuda-llvm --enable-cuvid --enable-dxva2 --enable-d3d11va --enable-d3d12va --enable-ffnvcodec --enable-libvpl --enable-nvdec --enable-nvenc --enable-vaapi --enable-libgme --enable-libopenmpt --enable-libopencore-amrwb --enable-libmp3lame --enable-libtheora --enable-libvo-amrwbenc --enable-libgsm --enable-libopencore-amrnb --enable-libopus --enable-libspeex --enable-libvorbis --enable-librubberband\n",
      "  libavutil      59.  8.100 / 59.  8.100\n",
      "  libavcodec     61.  3.100 / 61.  3.100\n",
      "  libavformat    61.  1.100 / 61.  1.100\n",
      "  libavdevice    61.  1.100 / 61.  1.100\n",
      "  libavfilter    10.  1.100 / 10.  1.100\n",
      "  libswscale      8.  1.100 /  8.  1.100\n",
      "  libswresample   5.  1.100 /  5.  1.100\n",
      "  libpostproc    58.  1.100 / 58.  1.100\n",
      "[in#0 @ 000001914d327480] Error opening input: Invalid data found when processing input\n",
      "Error opening input file C:\\Users\\cfune\\AppData\\Local\\Temp\\gradio\\6cd14e6a83c68abbf1d493566347bdc464f6df92875d74f16a5869ce47190715\\audio.wav.\n",
      "Error opening input files: Invalid data found when processing input\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Users\\Carlos\\Documents\\Code\\AI_media\\env\\Lib\\site-packages\\gradio\\queueing.py\", line 625, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Users\\Carlos\\Documents\\Code\\AI_media\\env\\Lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Users\\Carlos\\Documents\\Code\\AI_media\\env\\Lib\\site-packages\\gradio\\blocks.py\", line 2143, in process_api\n",
      "    inputs = await self.preprocess_data(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Users\\Carlos\\Documents\\Code\\AI_media\\env\\Lib\\site-packages\\gradio\\blocks.py\", line 1816, in preprocess_data\n",
      "    processed_input.append(block.preprocess(inputs_cached))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Users\\Carlos\\Documents\\Code\\AI_media\\env\\Lib\\site-packages\\gradio\\components\\audio.py\", line 264, in preprocess\n",
      "    return processing_utils.audio_from_file(payload.path)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Users\\Carlos\\Documents\\Code\\AI_media\\env\\Lib\\site-packages\\gradio\\processing_utils.py\", line 701, in audio_from_file\n",
      "    audio = AudioSegment.from_file(filename)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Users\\Carlos\\Documents\\Code\\AI_media\\env\\Lib\\site-packages\\pydub\\audio_segment.py\", line 773, in from_file\n",
      "    raise CouldntDecodeError(\n",
      "pydub.exceptions.CouldntDecodeError: Decoding failed. ffmpeg returned error code: 3199971767\n",
      "\n",
      "Output from ffmpeg/avlib:\n",
      "\n",
      "ffmpeg version 7.0-essentials_build-www.gyan.dev Copyright (c) 2000-2024 the FFmpeg developers\n",
      "  built with gcc 13.2.0 (Rev5, Built by MSYS2 project)\n",
      "  configuration: --enable-gpl --enable-version3 --enable-static --disable-w32threads --disable-autodetect --enable-fontconfig --enable-iconv --enable-gnutls --enable-libxml2 --enable-gmp --enable-bzlib --enable-lzma --enable-zlib --enable-libsrt --enable-libssh --enable-libzmq --enable-avisynth --enable-sdl2 --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxvid --enable-libaom --enable-libopenjpeg --enable-libvpx --enable-mediafoundation --enable-libass --enable-libfreetype --enable-libfribidi --enable-libharfbuzz --enable-libvidstab --enable-libvmaf --enable-libzimg --enable-amf --enable-cuda-llvm --enable-cuvid --enable-dxva2 --enable-d3d11va --enable-d3d12va --enable-ffnvcodec --enable-libvpl --enable-nvdec --enable-nvenc --enable-vaapi --enable-libgme --enable-libopenmpt --enable-libopencore-amrwb --enable-libmp3lame --enable-libtheora --enable-libvo-amrwbenc --enable-libgsm --enable-libopencore-amrnb --enable-libopus --enable-libspeex --enable-libvorbis --enable-librubberband\n",
      "  libavutil      59.  8.100 / 59.  8.100\n",
      "  libavcodec     61.  3.100 / 61.  3.100\n",
      "  libavformat    61.  1.100 / 61.  1.100\n",
      "  libavdevice    61.  1.100 / 61.  1.100\n",
      "  libavfilter    10.  1.100 / 10.  1.100\n",
      "  libswscale      8.  1.100 /  8.  1.100\n",
      "  libswresample   5.  1.100 /  5.  1.100\n",
      "  libpostproc    58.  1.100 / 58.  1.100\n",
      "[in#0 @ 0000028310967480] Error opening input: Invalid data found when processing input\n",
      "Error opening input file C:\\Users\\cfune\\AppData\\Local\\Temp\\gradio\\6cd14e6a83c68abbf1d493566347bdc464f6df92875d74f16a5869ce47190715\\audio.wav.\n",
      "Error opening input files: Invalid data found when processing input\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from transformers import pipeline\n",
    "import numpy as np\n",
    "\n",
    "transcriber = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-base.en\")\n",
    "\n",
    "def transcribe(stream, new_chunk):\n",
    "    sr, y = new_chunk\n",
    "    \n",
    "    # Convert to mono if stereo\n",
    "    if y.ndim > 1:\n",
    "        y = y.mean(axis=1)\n",
    "        \n",
    "    y = y.astype(np.float32)\n",
    "    y /= np.max(np.abs(y))\n",
    "\n",
    "    if stream is not None:\n",
    "        stream = np.concatenate([stream, y])\n",
    "    else:\n",
    "        stream = y\n",
    "    return stream, transcriber({\"sampling_rate\": sr, \"raw\": stream})[\"text\"]  \n",
    "\n",
    "demo = gr.Interface(\n",
    "    transcribe,\n",
    "    [\"state\", gr.Audio(sources=[\"microphone\"], streaming=True)],\n",
    "    [\"state\", \"text\"],\n",
    "    live=True,\n",
    ")\n",
    "\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60208284",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
