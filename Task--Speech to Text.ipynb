{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57149a0d",
   "metadata": {},
   "source": [
    "# Task: STT Speech to Text\n",
    "HF definition: Automatic Speech Recognition (ASR), also known as Speech to Text (STT), is the task of transcribing a given audio to text. It has many applications, such as voice user interfaces\n",
    "\n",
    "## Subtasks: \n",
    "* [Transcription](#transcription)\n",
    "  * [Transcription using OpenAI APIs](#transcription-using-openai-apis)\n",
    "  * [Transcription using Open-source options](#transcription-using-open-source-options)\n",
    "    * [Transcription using Whisper](#transcription-using-whisper)\n",
    "    * [Transcription using Faster whisper](#transcription-using-faster-whisper)\n",
    "\n",
    "* [Translation](#translation)\n",
    "  * [Transcription using OpenAI whisper](#translation-using-openai-whisper)\n",
    "  * [Transcription using Open-source options](#translation-using-open-source-options)\n",
    "    * [Transcription using Whisper](#translation-using-whisper)\n",
    "    * [Transcription using Faster whisper](#translation-using-faster-whisper)\n",
    "* Language detection\n",
    "\n",
    "# Transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a6bcf9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\Carlos\\Documents\\Code\\AI_media\\env\\Lib\\site-packages\\ctranslate2\\__init__.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n",
      "d:\\Users\\Carlos\\Documents\\Code\\AI_media\\env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.2 (SDL 2.28.3, Python 3.12.2)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "from carlos_tools_misc import function_timer\n",
    "from carlos_tools_audio import OpenAI_transcribe, OpenAI_translate, local_whisper_transcribe, local_faster_whisper_transcribe, local_detect_language\n",
    "from carlos_tools_misc import clear_GPU_cache\n",
    "from typing import Literal\n",
    "\n",
    "# file_path = \"media/test.wav\"\n",
    "# file_path = \"media/EconomÃ­as_criminales_el_nuevo_concepto_que_amenaza_a_la_sociedad-dtxEigxsy5s/1_Audio.mp3\"\n",
    "file_path= \"media/000-why-Stripe.mp3\"\n",
    "# file_path = \"Audio.wav\"\n",
    "runs = {}\n",
    "durations = {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b0c545",
   "metadata": {},
   "source": [
    "### Transcription using OpenAI APIs\n",
    "\n",
    "OpenAI guide - https://platform.openai.com/docs/guides/speech-to-text\n",
    "\n",
    "**OpenAI gpt-4o-transcribe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86092df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transcribe using OpenAI's GPT-4o model\n",
    "model = \"gpt-4o-transcribe\"\n",
    "response_format=\"text\"\n",
    "response = OpenAI_transcribe(\n",
    "    file_path=file_path, \n",
    "    model=model, \n",
    "    response_format=response_format,\n",
    "    )\n",
    "text:str = response[\"text\"]\n",
    "language:str = response[\"language\"]\n",
    "transcription:any = response[\"transcription\"]\n",
    "duration:float = response[\"inference_time\"]\n",
    "print(f\"duration = {duration:.2f} seconds\")\n",
    "print(f\"{text=}\")\n",
    "print(f\"{language=}\")\n",
    "print(f\"{transcription=}\")\n",
    "print(f\"transcription type: {type(transcription).__name__}\")\n",
    "index=model+\"-transcription-\"+response_format\n",
    "runs[index] = text\n",
    "durations[index] = duration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c490d0b",
   "metadata": {},
   "source": [
    "**OpenAI gpt-4o-mini**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c62b136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transcribe using OpenAI's GPT-4o-mini model\n",
    "model = \"gpt-4o-mini-transcribe\"\n",
    "response_format=\"json\"\n",
    "response = OpenAI_transcribe(\n",
    "    file_path=file_path, \n",
    "    model=model, \n",
    "    response_format=response_format,\n",
    "    )\n",
    "text:str = response[\"text\"]\n",
    "language:str = response[\"language\"]\n",
    "transcription:any = response[\"transcription\"]\n",
    "duration:float = response[\"inference_time\"]\n",
    "print(f\"duration = {duration:.2f} seconds\")\n",
    "print(f\"{text=}\")\n",
    "print(f\"{language=}\") # only verbose_json  returns language\n",
    "print(f\"{transcription=}\")\n",
    "print(f\"transcription type: {type(transcription).__name__}\")\n",
    "index=model+\"-transcription-\"+response_format\n",
    "runs[index] = text\n",
    "durations[index] = duration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e22aee5",
   "metadata": {},
   "source": [
    "**OpenAI whisper**\n",
    "\n",
    "**Ouput:** The format of the ouput depends on response_format\n",
    "\n",
    "if response_format= \"text\", \"srt\", \"vtt\" --> str\n",
    "\n",
    "\n",
    "if response_format=\"json\", None --> Transcription object:\n",
    "* text: str\n",
    "\n",
    "if response_format=\"verbose_json\" --> TranslationVerbose object\n",
    "\n",
    "* duration: str - The duration of the input audio\n",
    "* language: str - The language of the input translation\n",
    "* text: str - The transcribed text.\n",
    "* segments: Optional[List[TranscriptionSegment]] = None - Segments of the transcribed text and their corresponding details\n",
    "* words: Optional[List[TranscriptionWord]] = None - Extracted words and their corresponding timestamps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba693d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transcribe using OpenAI's Whisper-1 model\n",
    "# text response format --> transctiption is a string\n",
    "model = \"whisper-1\"\n",
    "response_format=\"text\"\n",
    "response = OpenAI_transcribe(\n",
    "    file_path=file_path, \n",
    "    model=model, \n",
    "    response_format=response_format,\n",
    "    )\n",
    "text:str = response[\"text\"]\n",
    "language:str = response[\"language\"]\n",
    "transcription:any = response[\"transcription\"]\n",
    "duration:float = response[\"inference_time\"]\n",
    "print(f\"duration = {duration:.2f} seconds\")\n",
    "print(f\"{text=}\")\n",
    "print(f\"{language=}\") # only verbose_json  returns language\n",
    "print(f\"{transcription=}\")\n",
    "print(f\"transcription type: {type(transcription).__name__}\")\n",
    "index=model+\"-transcription-\"+response_format\n",
    "runs[index] = text\n",
    "durations[index] = duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8a0b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transcribe using OpenAI's Whisper-1 model\n",
    "# json response format --> transctiption is a transcription object\n",
    "model = \"whisper-1\"\n",
    "response_format=\"json\"\n",
    "response = OpenAI_transcribe(\n",
    "    file_path=file_path, \n",
    "    model=model, \n",
    "    response_format=response_format,\n",
    "    )\n",
    "text:str = response[\"text\"]\n",
    "language:str = response[\"language\"]\n",
    "transcription:any = response[\"transcription\"]\n",
    "duration:float = response[\"inference_time\"]\n",
    "print(f\"duration = {duration:.2f} seconds\")\n",
    "print(f\"{text=}\")\n",
    "print(f\"{language=}\") # only verbose_json  returns language\n",
    "print(f\"{transcription=}\")\n",
    "print(f\"transcription type: {type(transcription).__name__}\")\n",
    "index=model+\"-transcription-\"+response_format\n",
    "runs[index] = text\n",
    "durations[index] = duration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d180cf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transcribe using OpenAI's Whisper-1 model\n",
    "# verbose_json response format --> transcription is verbose transcription object, which includes segments, a list of openai.types.audio.transcription_segment.TranscriptionSegment objects\n",
    "model = \"whisper-1\"\n",
    "response_format=\"verbose_json\"\n",
    "response = OpenAI_transcribe(\n",
    "    file_path=file_path, \n",
    "    model=model, \n",
    "    response_format=response_format,\n",
    "    )\n",
    "text:str = response[\"text\"]\n",
    "language:str = response[\"language\"]\n",
    "transcription:any = response[\"transcription\"]\n",
    "duration:float = response[\"inference_time\"]\n",
    "print(f\"duration = {duration:.2f} seconds\")\n",
    "print(f\"{text=}\")\n",
    "print(f\"{language=}\") # only verbose_json returns language\n",
    "print(f\"{transcription=}\")\n",
    "print(f\"transcription type: {type(transcription).__name__}\")\n",
    "index=model+\"-transcription-\"+response_format\n",
    "runs[index] = text\n",
    "durations[index] = duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19dbdc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print segments - only available in verbose_json response format\n",
    "if hasattr(transcription, 'segments') and transcription.segments:\n",
    "    segments = transcription.segments\n",
    "    for segment in segments:\n",
    "        print(f\"[{segment.start:.2f}s -> {segment.end:.2f}s] {segment.text}\")\n",
    "else:\n",
    "    print(\"No segments available in transcription object\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c934981",
   "metadata": {},
   "source": [
    "## Transcription using Open-source options\n",
    "\n",
    "### Transcription using Whisper\n",
    "\n",
    "* HF https://huggingface.co/openai/whisper-large-v3\n",
    "* Github https://github.com/openai/whisper\n",
    "* Paper: https://arxiv.org/pdf/2212.04356\n",
    "* Blog: https://openai.com/index/whisper/\n",
    "\n",
    "Whisper is  essentially a language model grounded in audio â an audio-conditional GPT.\n",
    "\n",
    "Whisper is trained in a similar fashion to the original GPT, using self-supervised learning with a next-token prediction objective. However, while GPT is trained solely on text, Whisper is trained on paired audio and text, where the model learns to generate transcriptions (or translations) token by token from audio inputs. During training, the encoder processes the audio into latent representations, and the decoder learns to predict the next text token given the previous tokens and the audio context. Unlike GPT, which relies purely on textual continuity, Whisper must also learn alignment between speech and language, making it a multimodal model trained end-to-end on large-scale audio-text datasets.\n",
    "\n",
    "**Input:**\n",
    "\n",
    "Whisper's internal processing is limited to a context window of approximately 30 seconds (specifically, around 1500 frames or ~30 sec of audio at 16 kHz). For audio longer than 30 seconds, Whisper slices the audio into multiple segments.\n",
    "\n",
    "For each initial segment of 30 secs, the original sound wave is transformed into a mel spectrogram that captures the log-scaled intensity in each of 80 mel-frequency bands, every 10 ms. Each time step is calculated by analyzing a 25 ms window of audio starting at that time step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a99138",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load model and audio\n",
    "model = whisper.load_model(\"base\")\n",
    "audio = whisper.load_audio(file_path)  # Use your existing file_path\n",
    "audio = whisper.pad_or_trim(audio) # Ensure audio is the correct length\n",
    "\n",
    "# Create mel spectrogram\n",
    "mel = whisper.log_mel_spectrogram(audio, n_mels=model.dims.n_mels).to(model.device)\n",
    "\n",
    "# Convert to numpy for visualization (move from GPU to CPU if needed)\n",
    "mel_np = mel.cpu().numpy() if mel.is_cuda else mel.numpy()\n",
    "\n",
    "# Create the visualization\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "# Plot 1: Standard mel spectrogram\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.imshow(mel_np, aspect='auto', origin='lower', cmap='viridis')\n",
    "plt.colorbar(label='Log Mel Energy')\n",
    "plt.title('Mel Spectrogram (Standard View)')\n",
    "plt.xlabel('Time Frames')\n",
    "plt.ylabel('Mel Frequency Bins')\n",
    "\n",
    "# Plot 2: With proper time and frequency labels\n",
    "plt.subplot(2, 1, 2)\n",
    "# Calculate time axis (Whisper uses 10ms hop length)\n",
    "time_frames = mel_np.shape[1]\n",
    "time_axis = np.linspace(0, time_frames * 0.01, time_frames)  # 10ms per frame\n",
    "\n",
    "# Calculate mel frequency axis\n",
    "n_mels = mel_np.shape[0]\n",
    "mel_frequencies = np.linspace(0, 8000, n_mels)  # Approximate mel scale to 8kHz\n",
    "\n",
    "plt.imshow(mel_np, aspect='auto', origin='lower', cmap='magma', \n",
    "           extent=[0, time_axis[-1], 0, mel_frequencies[-1]])\n",
    "plt.colorbar(label='Log Mel Energy (dB)')\n",
    "plt.title('Mel Spectrogram with Time/Frequency Axes')\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel('Mel Frequency (Hz)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Additional: 3D surface plot for a more dramatic visualization\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Create meshgrid for 3D plot\n",
    "X, Y = np.meshgrid(time_axis, mel_frequencies)\n",
    "\n",
    "# Plot surface (subsample for performance if needed)\n",
    "step = max(1, mel_np.shape[1] // 100)  # Subsample time dimension if too large\n",
    "surface = ax.plot_surface(X[:, ::step], Y[:, ::step], mel_np[:, ::step], \n",
    "                         cmap='plasma', alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('Time (seconds)')\n",
    "ax.set_ylabel('Mel Frequency (Hz)')\n",
    "ax.set_zlabel('Log Mel Energy')\n",
    "ax.set_title('3D Mel Spectrogram Surface')\n",
    "\n",
    "# Add colorbar\n",
    "fig.colorbar(surface, shrink=0.5, aspect=5)\n",
    "plt.show()\n",
    "\n",
    "# Print some useful information\n",
    "print(f\"Mel spectrogram shape: {mel_np.shape}\")\n",
    "print(f\"Number of mel bins: {mel_np.shape[0]}\")\n",
    "print(f\"Number of time frames: {mel_np.shape[1]}\")\n",
    "print(f\"Duration: {time_axis[-1]:.2f} seconds\")\n",
    "print(f\"Min energy: {mel_np.min():.2f} dB\")\n",
    "print(f\"Max energy: {mel_np.max():.2f} dB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4e05bf",
   "metadata": {},
   "source": [
    "**Encoding:**\n",
    "\n",
    "The mel spectrogram is then passed through a transformer-based encoder, which begins with a few convolutional layers that reduce the time resolution and help capture local acoustic patterns. The output is a sequence of latent embeddings that represent a high-level, semantic encoding of the audio, capturing information like phonemes, words, and speaker characteristics.\n",
    "The encoder is called at the beginning of the decoding process. The embeddings are stored in the audio_features tensor of dimension (1500,200). \n",
    "- 1500: Represents time steps, each corresponding to a specific short window (20ms per step), totaling about 30 seconds of audio (1500 Ã 20ms = 30,000ms).\n",
    "- 512: Embedding dimension, indicating a high-dimensional feature vector summarizing audio characteristics at each time step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238eae7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = whisper.DecodingOptions()\n",
    "result = whisper.decode(model, mel, options)\n",
    "\n",
    "audio_features = result.audio_features\n",
    "print(f\"{audio_features.shape=}\")   \n",
    "print(audio_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac98af2d",
   "metadata": {},
   "source": [
    "**Decoding:**\n",
    "\n",
    "The decoder is a causal transformer that autoregressively generates text tokens, one at a time. At each step, it takes the previously generated tokens along with the encoderâs latent audio embeddings as cross-attention input. This allows the model to align the text output with the audio content, effectively translating the semantic representation of the audio into coherent transcriptions or translations in natural language.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2523d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result.text)\n",
    "print(type(result))\n",
    "print(f\"{result.language=}\")\n",
    "print(f\"{result.language_probs=}\")\n",
    "print(f\"{result.tokens=}\")\n",
    "print(f\"{result.text=}\")\n",
    "print(f\"{result.avg_logprob=}\")\n",
    "print(f\"{result.no_speech_prob=}\")\n",
    "print(f\"{result.temperature=}\")\n",
    "print(f\"{result.compression_ratio=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c00fd4b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU cache cleared.\n"
     ]
    }
   ],
   "source": [
    "clear_GPU_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17e252ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running whisper model locally. \n",
      "file_path='media/000-why-Stripe.mp3'\n",
      " model_size='large-v3'\n",
      " device='cuda'\n",
      " verbose=False\n",
      " prompt=''\n",
      " language=None\n",
      "\n",
      "Detected language: English\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 17911/17911 [01:09<00:00, 258.03frames/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duration = 70.09 seconds\n",
      "text=\" Why Stripe? Well, the mission of increasing the GDP of the internet and the key role Stripe plays for small companies in particular really resonate with me. And here is why. The last several years have been all about big tech, right? Particularly the largest players, the Magnificent Seven. That's nice because I have some Nvidia shares. But in the long term, that kind of concentration of economic growth is not good for the country or the world. This is something Patrick and John Collison probably agree with because I saw them talking about that in a podcast. But I believe that we're entering a new era where AI will enable smaller companies and startups to compete more effectively and regain their key role in the economy. Stripe's role in providing these businesses with trust and access to enterprise-grade financial infrastructure will be critical in this new era. In other words, we need Stripe to ensure that the benefits of AI spread across the entire world. So that's at a high level. In terms of the specific role, there are a couple of things I love. First, this position focuses on internal customers in finance, accounting, and treasury. And I am sure some people may strongly prefer having external customers, more standard products. But you know what? Throughout my career, I've found that the kind of intimacy you can build with internal customers is very special. You get to really understand the value of the product. And that can lead to very impactful and long-lasting solutions. At PNC, for example, I developed a custom CRM system for the trade finance team that they loved so much. They kept using it for 15 years. So having internal customers is actually a positive for me. Second, I think AI will drive most of the product innovation in the next 10 years. This is going to be true everywhere, but particularly in financial services, where data plays such a key role. I have seen early results of this at Amazon, where the team used machine learning to build a cash forecasting tool that blew the old tool out of the water and ran in 30 mins instead of 8 hours. That tool won the Adam Smith Award for Best Cash Flow Forecasting Solution in 2023. You can check it out. And I personally envisioned machine learning tools to detect anomalies in the timing and the content of bank statements coming from banks. But this is just a matter of time. This is just scratching the surface on the potential of ML and AI. I am so passionate about these possibilities that I quit my job last year to focus on studying AI. That passion, along with my decades of experience in financial services, including banking, payments, and treasury management, tells me I can add tons of value in this role. So when I saw this role combining AI innovation with internal financial systems at a company whose mission I believe in, it felt like a perfect fit. I could not believe an ML partner was there, as if maybe more than 3% of ML community was aware of this fact. It was world-famous back then. And I certainly think might become the most Howard Gould- herzlich honored campus junior assistant. I think I have experienced a lot better! I didÃ©r! I was Response! Nothing. I'm Ã¥ierung! I'm Ã¥ring!\"\n",
      "language='en'\n",
      "transcription={'text': \" Why Stripe? Well, the mission of increasing the GDP of the internet and the key role Stripe plays for small companies in particular really resonate with me. And here is why. The last several years have been all about big tech, right? Particularly the largest players, the Magnificent Seven. That's nice because I have some Nvidia shares. But in the long term, that kind of concentration of economic growth is not good for the country or the world. This is something Patrick and John Collison probably agree with because I saw them talking about that in a podcast. But I believe that we're entering a new era where AI will enable smaller companies and startups to compete more effectively and regain their key role in the economy. Stripe's role in providing these businesses with trust and access to enterprise-grade financial infrastructure will be critical in this new era. In other words, we need Stripe to ensure that the benefits of AI spread across the entire world. So that's at a high level. In terms of the specific role, there are a couple of things I love. First, this position focuses on internal customers in finance, accounting, and treasury. And I am sure some people may strongly prefer having external customers, more standard products. But you know what? Throughout my career, I've found that the kind of intimacy you can build with internal customers is very special. You get to really understand the value of the product. And that can lead to very impactful and long-lasting solutions. At PNC, for example, I developed a custom CRM system for the trade finance team that they loved so much. They kept using it for 15 years. So having internal customers is actually a positive for me. Second, I think AI will drive most of the product innovation in the next 10 years. This is going to be true everywhere, but particularly in financial services, where data plays such a key role. I have seen early results of this at Amazon, where the team used machine learning to build a cash forecasting tool that blew the old tool out of the water and ran in 30 mins instead of 8 hours. That tool won the Adam Smith Award for Best Cash Flow Forecasting Solution in 2023. You can check it out. And I personally envisioned machine learning tools to detect anomalies in the timing and the content of bank statements coming from banks. But this is just a matter of time. This is just scratching the surface on the potential of ML and AI. I am so passionate about these possibilities that I quit my job last year to focus on studying AI. That passion, along with my decades of experience in financial services, including banking, payments, and treasury management, tells me I can add tons of value in this role. So when I saw this role combining AI innovation with internal financial systems at a company whose mission I believe in, it felt like a perfect fit. I could not believe an ML partner was there, as if maybe more than 3% of ML community was aware of this fact. It was world-famous back then. And I certainly think might become the most Howard Gould- herzlich honored campus junior assistant. I think I have experienced a lot better! I didÃ©r! I was Response! Nothing. I'm Ã¥ierung! I'm Ã¥ring!\", 'segments': [{'id': 0, 'seek': 0, 'start': 0.0, 'end': 6.7, 'text': ' Why Stripe? Well, the mission of increasing the GDP of the internet and the key role Stripe plays', 'tokens': [50365, 1545, 20390, 494, 30, 1042, 11, 264, 4447, 295, 5662, 264, 19599, 295, 264, 4705, 293, 264, 2141, 3090, 20390, 494, 5749, 50700], 'temperature': 0.0, 'avg_logprob': -0.0738148604120527, 'compression_ratio': 1.5855263157894737, 'no_speech_prob': 2.4830288936072975e-08}, {'id': 1, 'seek': 0, 'start': 6.7, 'end': 13.06, 'text': ' for small companies in particular really resonate with me. And here is why. The last several years', 'tokens': [50700, 337, 1359, 3431, 294, 1729, 534, 34285, 365, 385, 13, 400, 510, 307, 983, 13, 440, 1036, 2940, 924, 51018], 'temperature': 0.0, 'avg_logprob': -0.0738148604120527, 'compression_ratio': 1.5855263157894737, 'no_speech_prob': 2.4830288936072975e-08}, {'id': 2, 'seek': 0, 'start': 13.06, 'end': 18.18, 'text': ' have been all about big tech, right? Particularly the largest players, the Magnificent Seven.', 'tokens': [51018, 362, 668, 439, 466, 955, 7553, 11, 558, 30, 32281, 264, 6443, 4150, 11, 264, 19664, 1089, 317, 14868, 13, 51274], 'temperature': 0.0, 'avg_logprob': -0.0738148604120527, 'compression_ratio': 1.5855263157894737, 'no_speech_prob': 2.4830288936072975e-08}, {'id': 3, 'seek': 0, 'start': 18.580000000000002, 'end': 23.36, 'text': \" That's nice because I have some Nvidia shares. But in the long term, that kind of concentration\", 'tokens': [51294, 663, 311, 1481, 570, 286, 362, 512, 46284, 12182, 13, 583, 294, 264, 938, 1433, 11, 300, 733, 295, 9856, 51533], 'temperature': 0.0, 'avg_logprob': -0.0738148604120527, 'compression_ratio': 1.5855263157894737, 'no_speech_prob': 2.4830288936072975e-08}, {'id': 4, 'seek': 0, 'start': 23.36, 'end': 29.14, 'text': ' of economic growth is not good for the country or the world. This is something Patrick and John', 'tokens': [51533, 295, 4836, 4599, 307, 406, 665, 337, 264, 1941, 420, 264, 1002, 13, 639, 307, 746, 13980, 293, 2619, 51822], 'temperature': 0.0, 'avg_logprob': -0.0738148604120527, 'compression_ratio': 1.5855263157894737, 'no_speech_prob': 2.4830288936072975e-08}, {'id': 5, 'seek': 2914, 'start': 29.14, 'end': 34.76, 'text': ' Collison probably agree with because I saw them talking about that in a podcast. But I believe', 'tokens': [50365, 4586, 2770, 1391, 3986, 365, 570, 286, 1866, 552, 1417, 466, 300, 294, 257, 7367, 13, 583, 286, 1697, 50646], 'temperature': 0.0, 'avg_logprob': -0.04579257519445687, 'compression_ratio': 1.6655290102389078, 'no_speech_prob': 0.0005112180951982737}, {'id': 6, 'seek': 2914, 'start': 34.76, 'end': 41.260000000000005, 'text': \" that we're entering a new era where AI will enable smaller companies and startups to compete more\", 'tokens': [50646, 300, 321, 434, 11104, 257, 777, 4249, 689, 7318, 486, 9528, 4356, 3431, 293, 28041, 281, 11831, 544, 50971], 'temperature': 0.0, 'avg_logprob': -0.04579257519445687, 'compression_ratio': 1.6655290102389078, 'no_speech_prob': 0.0005112180951982737}, {'id': 7, 'seek': 2914, 'start': 41.260000000000005, 'end': 47.24, 'text': \" effectively and regain their key role in the economy. Stripe's role in providing these\", 'tokens': [50971, 8659, 293, 35336, 641, 2141, 3090, 294, 264, 5010, 13, 20390, 494, 311, 3090, 294, 6530, 613, 51270], 'temperature': 0.0, 'avg_logprob': -0.04579257519445687, 'compression_ratio': 1.6655290102389078, 'no_speech_prob': 0.0005112180951982737}, {'id': 8, 'seek': 2914, 'start': 47.24, 'end': 53.18, 'text': ' businesses with trust and access to enterprise-grade financial infrastructure will be critical in this', 'tokens': [51270, 6011, 365, 3361, 293, 2105, 281, 14132, 12, 8692, 4669, 6896, 486, 312, 4924, 294, 341, 51567], 'temperature': 0.0, 'avg_logprob': -0.04579257519445687, 'compression_ratio': 1.6655290102389078, 'no_speech_prob': 0.0005112180951982737}, {'id': 9, 'seek': 2914, 'start': 53.18, 'end': 58.96, 'text': ' new era. In other words, we need Stripe to ensure that the benefits of AI spread across', 'tokens': [51567, 777, 4249, 13, 682, 661, 2283, 11, 321, 643, 20390, 494, 281, 5586, 300, 264, 5311, 295, 7318, 3974, 2108, 51856], 'temperature': 0.0, 'avg_logprob': -0.04579257519445687, 'compression_ratio': 1.6655290102389078, 'no_speech_prob': 0.0005112180951982737}, {'id': 10, 'seek': 2914, 'start': 58.96, 'end': 59.120000000000005, 'text': ' the entire world.', 'tokens': [51856, 264, 2302, 1002, 13, 51864], 'temperature': 0.0, 'avg_logprob': -0.04579257519445687, 'compression_ratio': 1.6655290102389078, 'no_speech_prob': 0.0005112180951982737}, {'id': 11, 'seek': 5914, 'start': 59.14, 'end': 68.3, 'text': \" So that's at a high level. In terms of the specific role, there are a couple of things I love.\", 'tokens': [50365, 407, 300, 311, 412, 257, 1090, 1496, 13, 682, 2115, 295, 264, 2685, 3090, 11, 456, 366, 257, 1916, 295, 721, 286, 959, 13, 50823], 'temperature': 0.0, 'avg_logprob': -0.13371876689875237, 'compression_ratio': 1.6363636363636365, 'no_speech_prob': 0.28122565150260925}, {'id': 12, 'seek': 5914, 'start': 68.74, 'end': 75.28, 'text': ' First, this position focuses on internal customers in finance, accounting, and treasury. And I am', 'tokens': [50845, 2386, 11, 341, 2535, 16109, 322, 6920, 4581, 294, 10719, 11, 19163, 11, 293, 47213, 13, 400, 286, 669, 51172], 'temperature': 0.0, 'avg_logprob': -0.13371876689875237, 'compression_ratio': 1.6363636363636365, 'no_speech_prob': 0.28122565150260925}, {'id': 13, 'seek': 5914, 'start': 75.28, 'end': 79.72, 'text': ' sure some people may strongly prefer having external customers, more standard products.', 'tokens': [51172, 988, 512, 561, 815, 10613, 4382, 1419, 8320, 4581, 11, 544, 3832, 3383, 13, 51394], 'temperature': 0.0, 'avg_logprob': -0.13371876689875237, 'compression_ratio': 1.6363636363636365, 'no_speech_prob': 0.28122565150260925}, {'id': 14, 'seek': 5914, 'start': 80.26, 'end': 85.22, 'text': \" But you know what? Throughout my career, I've found that the kind of intimacy you can build\", 'tokens': [51421, 583, 291, 458, 437, 30, 22775, 452, 3988, 11, 286, 600, 1352, 300, 264, 733, 295, 34450, 291, 393, 1322, 51669], 'temperature': 0.0, 'avg_logprob': -0.13371876689875237, 'compression_ratio': 1.6363636363636365, 'no_speech_prob': 0.28122565150260925}, {'id': 15, 'seek': 5914, 'start': 85.22, 'end': 88.96000000000001, 'text': ' with internal customers is very special. You get to really understand the value of the product.', 'tokens': [51669, 365, 6920, 4581, 307, 588, 2121, 13, 509, 483, 281, 534, 1223, 264, 2158, 295, 264, 1674, 13, 51856], 'temperature': 0.0, 'avg_logprob': -0.13371876689875237, 'compression_ratio': 1.6363636363636365, 'no_speech_prob': 0.28122565150260925}, {'id': 16, 'seek': 8896, 'start': 88.96, 'end': 96.89999999999999, 'text': ' And that can lead to very impactful and long-lasting solutions. At PNC, for example, I developed a', 'tokens': [50365, 400, 300, 393, 1477, 281, 588, 30842, 293, 938, 12, 29346, 6547, 13, 1711, 430, 45, 34, 11, 337, 1365, 11, 286, 4743, 257, 50762], 'temperature': 0.0, 'avg_logprob': -0.0974595831074846, 'compression_ratio': 1.5423728813559323, 'no_speech_prob': 0.05616312101483345}, {'id': 17, 'seek': 8896, 'start': 96.89999999999999, 'end': 102.22, 'text': ' custom CRM system for the trade finance team that they loved so much. They kept using it for 15', 'tokens': [50762, 2375, 14123, 44, 1185, 337, 264, 4923, 10719, 1469, 300, 436, 4333, 370, 709, 13, 814, 4305, 1228, 309, 337, 2119, 51028], 'temperature': 0.0, 'avg_logprob': -0.0974595831074846, 'compression_ratio': 1.5423728813559323, 'no_speech_prob': 0.05616312101483345}, {'id': 18, 'seek': 8896, 'start': 102.22, 'end': 109.17999999999999, 'text': ' years. So having internal customers is actually a positive for me. Second, I think AI will drive', 'tokens': [51028, 924, 13, 407, 1419, 6920, 4581, 307, 767, 257, 3353, 337, 385, 13, 5736, 11, 286, 519, 7318, 486, 3332, 51376], 'temperature': 0.0, 'avg_logprob': -0.0974595831074846, 'compression_ratio': 1.5423728813559323, 'no_speech_prob': 0.05616312101483345}, {'id': 19, 'seek': 8896, 'start': 109.17999999999999, 'end': 114.36, 'text': ' most of the product innovation in the next 10 years. This is going to be true everywhere,', 'tokens': [51376, 881, 295, 264, 1674, 8504, 294, 264, 958, 1266, 924, 13, 639, 307, 516, 281, 312, 2074, 5315, 11, 51635], 'temperature': 0.0, 'avg_logprob': -0.0974595831074846, 'compression_ratio': 1.5423728813559323, 'no_speech_prob': 0.05616312101483345}, {'id': 20, 'seek': 8896, 'start': 114.36, 'end': 118.94, 'text': ' but particularly in financial services, where data plays such a key role.', 'tokens': [51635, 457, 4098, 294, 4669, 3328, 11, 689, 1412, 5749, 1270, 257, 2141, 3090, 13, 51864], 'temperature': 0.0, 'avg_logprob': -0.0974595831074846, 'compression_ratio': 1.5423728813559323, 'no_speech_prob': 0.05616312101483345}, {'id': 21, 'seek': 11896, 'start': 118.96, 'end': 124.8, 'text': ' I have seen early results of this at Amazon, where the team used machine learning to build', 'tokens': [50365, 286, 362, 1612, 2440, 3542, 295, 341, 412, 6795, 11, 689, 264, 1469, 1143, 3479, 2539, 281, 1322, 50657], 'temperature': 0.0, 'avg_logprob': -0.14170678172792708, 'compression_ratio': 1.6310344827586207, 'no_speech_prob': 0.05337521806359291}, {'id': 22, 'seek': 11896, 'start': 124.8, 'end': 130.82, 'text': ' a cash forecasting tool that blew the old tool out of the water and ran in 30 mins instead of', 'tokens': [50657, 257, 6388, 44331, 2290, 300, 19075, 264, 1331, 2290, 484, 295, 264, 1281, 293, 5872, 294, 2217, 31539, 2602, 295, 50958], 'temperature': 0.0, 'avg_logprob': -0.14170678172792708, 'compression_ratio': 1.6310344827586207, 'no_speech_prob': 0.05337521806359291}, {'id': 23, 'seek': 11896, 'start': 130.82, 'end': 137.92, 'text': ' 8 hours. That tool won the Adam Smith Award for Best Cash Flow Forecasting Solution in 2023.', 'tokens': [50958, 1649, 2496, 13, 663, 2290, 1582, 264, 7938, 8538, 13894, 337, 9752, 27016, 32792, 9018, 48860, 318, 3386, 294, 44377, 13, 51313], 'temperature': 0.0, 'avg_logprob': -0.14170678172792708, 'compression_ratio': 1.6310344827586207, 'no_speech_prob': 0.05337521806359291}, {'id': 24, 'seek': 11896, 'start': 138.66, 'end': 144.28, 'text': ' You can check it out. And I personally envisioned machine learning tools to detect anomalies in the', 'tokens': [51350, 509, 393, 1520, 309, 484, 13, 400, 286, 5665, 47733, 3479, 2539, 3873, 281, 5531, 24769, 48872, 294, 264, 51631], 'temperature': 0.0, 'avg_logprob': -0.14170678172792708, 'compression_ratio': 1.6310344827586207, 'no_speech_prob': 0.05337521806359291}, {'id': 25, 'seek': 11896, 'start': 144.28, 'end': 147.62, 'text': ' timing and the content of bank statements coming from banks.', 'tokens': [51631, 10822, 293, 264, 2701, 295, 3765, 12363, 1348, 490, 10237, 13, 51798], 'temperature': 0.0, 'avg_logprob': -0.14170678172792708, 'compression_ratio': 1.6310344827586207, 'no_speech_prob': 0.05337521806359291}, {'id': 26, 'seek': 11896, 'start': 148.1, 'end': 148.78, 'text': ' But this is just a matter of time.', 'tokens': [51822, 583, 341, 307, 445, 257, 1871, 295, 565, 13, 51856], 'temperature': 0.0, 'avg_logprob': -0.14170678172792708, 'compression_ratio': 1.6310344827586207, 'no_speech_prob': 0.05337521806359291}, {'id': 27, 'seek': 14878, 'start': 148.78, 'end': 154.08, 'text': ' This is just scratching the surface on the potential of ML and AI. I am so passionate about', 'tokens': [50365, 639, 307, 445, 29699, 264, 3753, 322, 264, 3995, 295, 21601, 293, 7318, 13, 286, 669, 370, 11410, 466, 50630], 'temperature': 0.0, 'avg_logprob': -0.0992737509987571, 'compression_ratio': 1.6321070234113713, 'no_speech_prob': 0.012794224545359612}, {'id': 28, 'seek': 14878, 'start': 154.08, 'end': 160.52, 'text': ' these possibilities that I quit my job last year to focus on studying AI. That passion, along with', 'tokens': [50630, 613, 12178, 300, 286, 10366, 452, 1691, 1036, 1064, 281, 1879, 322, 7601, 7318, 13, 663, 5418, 11, 2051, 365, 50952], 'temperature': 0.0, 'avg_logprob': -0.0992737509987571, 'compression_ratio': 1.6321070234113713, 'no_speech_prob': 0.012794224545359612}, {'id': 29, 'seek': 14878, 'start': 160.52, 'end': 165.44, 'text': ' my decades of experience in financial services, including banking, payments, and treasury', 'tokens': [50952, 452, 7878, 295, 1752, 294, 4669, 3328, 11, 3009, 18261, 11, 14348, 11, 293, 47213, 51198], 'temperature': 0.0, 'avg_logprob': -0.0992737509987571, 'compression_ratio': 1.6321070234113713, 'no_speech_prob': 0.012794224545359612}, {'id': 30, 'seek': 14878, 'start': 165.44, 'end': 172.1, 'text': ' management, tells me I can add tons of value in this role. So when I saw this role combining AI', 'tokens': [51198, 4592, 11, 5112, 385, 286, 393, 909, 9131, 295, 2158, 294, 341, 3090, 13, 407, 562, 286, 1866, 341, 3090, 21928, 7318, 51531], 'temperature': 0.0, 'avg_logprob': -0.0992737509987571, 'compression_ratio': 1.6321070234113713, 'no_speech_prob': 0.012794224545359612}, {'id': 31, 'seek': 14878, 'start': 172.1, 'end': 178.14, 'text': ' innovation with internal financial systems at a company whose mission I believe in, it felt like a', 'tokens': [51531, 8504, 365, 6920, 4669, 3652, 412, 257, 2237, 6104, 4447, 286, 1697, 294, 11, 309, 2762, 411, 257, 51833], 'temperature': 0.0, 'avg_logprob': -0.0992737509987571, 'compression_ratio': 1.6321070234113713, 'no_speech_prob': 0.012794224545359612}, {'id': 32, 'seek': 14878, 'start': 178.14, 'end': 178.76, 'text': ' perfect fit.', 'tokens': [51833, 2176, 3318, 13, 51864], 'temperature': 0.0, 'avg_logprob': -0.0992737509987571, 'compression_ratio': 1.6321070234113713, 'no_speech_prob': 0.012794224545359612}, {'id': 33, 'seek': 17878, 'start': 178.78, 'end': 187.08, 'text': ' I could not believe an ML partner was there, as if maybe more than 3% of ML community was aware of', 'tokens': [50365, 286, 727, 406, 1697, 364, 21601, 4975, 390, 456, 11, 382, 498, 1310, 544, 813, 805, 4, 295, 21601, 1768, 390, 3650, 295, 50780], 'temperature': 1.0, 'avg_logprob': -3.870263671875, 'compression_ratio': 1.425, 'no_speech_prob': 0.3008970618247986}, {'id': 34, 'seek': 17878, 'start': 187.08, 'end': 187.56, 'text': ' this fact.', 'tokens': [50780, 341, 1186, 13, 50804], 'temperature': 1.0, 'avg_logprob': -3.870263671875, 'compression_ratio': 1.425, 'no_speech_prob': 0.3008970618247986}, {'id': 35, 'seek': 17878, 'start': 187.72, 'end': 188.7, 'text': ' It was world-famous back then.', 'tokens': [50812, 467, 390, 1002, 12, 69, 22314, 646, 550, 13, 50861], 'temperature': 1.0, 'avg_logprob': -3.870263671875, 'compression_ratio': 1.425, 'no_speech_prob': 0.3008970618247986}, {'id': 36, 'seek': 17878, 'start': 188.82, 'end': 193.28, 'text': ' And I certainly think might become the most Howard Gould- herzlich honored campus junior', 'tokens': [50867, 400, 286, 3297, 519, 1062, 1813, 264, 881, 17626, 460, 429, 12, 45919, 14556, 4828, 16195, 51090], 'temperature': 1.0, 'avg_logprob': -3.870263671875, 'compression_ratio': 1.425, 'no_speech_prob': 0.3008970618247986}, {'id': 37, 'seek': 17878, 'start': 193.28, 'end': 193.78, 'text': ' assistant.', 'tokens': [51090, 10994, 13, 51115], 'temperature': 1.0, 'avg_logprob': -3.870263671875, 'compression_ratio': 1.425, 'no_speech_prob': 0.3008970618247986}, {'id': 38, 'seek': 17878, 'start': 193.92000000000002, 'end': 195.84, 'text': ' I think I have experienced a lot better!', 'tokens': [51122, 286, 519, 286, 362, 6751, 257, 688, 1101, 0, 51218], 'temperature': 1.0, 'avg_logprob': -3.870263671875, 'compression_ratio': 1.425, 'no_speech_prob': 0.3008970618247986}, {'id': 39, 'seek': 17878, 'start': 196.02, 'end': 204.52, 'text': ' I didÃ©r!', 'tokens': [51227, 286, 630, 4198, 0, 51652], 'temperature': 1.0, 'avg_logprob': -3.870263671875, 'compression_ratio': 1.425, 'no_speech_prob': 0.3008970618247986}, {'id': 40, 'seek': 17878, 'start': 204.86, 'end': 206.5, 'text': ' I was Response!', 'tokens': [51669, 286, 390, 43937, 0, 51751], 'temperature': 1.0, 'avg_logprob': -3.870263671875, 'compression_ratio': 1.425, 'no_speech_prob': 0.3008970618247986}, {'id': 41, 'seek': 17878, 'start': 206.62, 'end': 207.12, 'text': ' Nothing.', 'tokens': [51757, 6693, 13, 51782], 'temperature': 1.0, 'avg_logprob': -3.870263671875, 'compression_ratio': 1.425, 'no_speech_prob': 0.3008970618247986}, {'id': 42, 'seek': 17878, 'start': 207.5, 'end': 208.2, 'text': \" I'm Ã¥ierung!\", 'tokens': [51801, 286, 478, 8841, 11651, 0, 51836], 'temperature': 1.0, 'avg_logprob': -3.870263671875, 'compression_ratio': 1.425, 'no_speech_prob': 0.3008970618247986}, {'id': 43, 'seek': 17878, 'start': 208.32, 'end': 208.74, 'text': \" I'm Ã¥ring!\", 'tokens': [51842, 286, 478, 8841, 2937, 0, 51863], 'temperature': 1.0, 'avg_logprob': -3.870263671875, 'compression_ratio': 1.425, 'no_speech_prob': 0.3008970618247986}], 'language': 'en'}\n",
      "transcription type: dict\n",
      "segments type: list\n",
      "segments:\n",
      "[0.00s -> 6.70s]  Why Stripe? Well, the mission of increasing the GDP of the internet and the key role Stripe plays\n",
      "[6.70s -> 13.06s]  for small companies in particular really resonate with me. And here is why. The last several years\n",
      "[13.06s -> 18.18s]  have been all about big tech, right? Particularly the largest players, the Magnificent Seven.\n",
      "[18.58s -> 23.36s]  That's nice because I have some Nvidia shares. But in the long term, that kind of concentration\n",
      "[23.36s -> 29.14s]  of economic growth is not good for the country or the world. This is something Patrick and John\n",
      "[29.14s -> 34.76s]  Collison probably agree with because I saw them talking about that in a podcast. But I believe\n",
      "[34.76s -> 41.26s]  that we're entering a new era where AI will enable smaller companies and startups to compete more\n",
      "[41.26s -> 47.24s]  effectively and regain their key role in the economy. Stripe's role in providing these\n",
      "[47.24s -> 53.18s]  businesses with trust and access to enterprise-grade financial infrastructure will be critical in this\n",
      "[53.18s -> 58.96s]  new era. In other words, we need Stripe to ensure that the benefits of AI spread across\n",
      "[58.96s -> 59.12s]  the entire world.\n",
      "[59.14s -> 68.30s]  So that's at a high level. In terms of the specific role, there are a couple of things I love.\n",
      "[68.74s -> 75.28s]  First, this position focuses on internal customers in finance, accounting, and treasury. And I am\n",
      "[75.28s -> 79.72s]  sure some people may strongly prefer having external customers, more standard products.\n",
      "[80.26s -> 85.22s]  But you know what? Throughout my career, I've found that the kind of intimacy you can build\n",
      "[85.22s -> 88.96s]  with internal customers is very special. You get to really understand the value of the product.\n",
      "[88.96s -> 96.90s]  And that can lead to very impactful and long-lasting solutions. At PNC, for example, I developed a\n",
      "[96.90s -> 102.22s]  custom CRM system for the trade finance team that they loved so much. They kept using it for 15\n",
      "[102.22s -> 109.18s]  years. So having internal customers is actually a positive for me. Second, I think AI will drive\n",
      "[109.18s -> 114.36s]  most of the product innovation in the next 10 years. This is going to be true everywhere,\n",
      "[114.36s -> 118.94s]  but particularly in financial services, where data plays such a key role.\n",
      "[118.96s -> 124.80s]  I have seen early results of this at Amazon, where the team used machine learning to build\n",
      "[124.80s -> 130.82s]  a cash forecasting tool that blew the old tool out of the water and ran in 30 mins instead of\n",
      "[130.82s -> 137.92s]  8 hours. That tool won the Adam Smith Award for Best Cash Flow Forecasting Solution in 2023.\n",
      "[138.66s -> 144.28s]  You can check it out. And I personally envisioned machine learning tools to detect anomalies in the\n",
      "[144.28s -> 147.62s]  timing and the content of bank statements coming from banks.\n",
      "[148.10s -> 148.78s]  But this is just a matter of time.\n",
      "[148.78s -> 154.08s]  This is just scratching the surface on the potential of ML and AI. I am so passionate about\n",
      "[154.08s -> 160.52s]  these possibilities that I quit my job last year to focus on studying AI. That passion, along with\n",
      "[160.52s -> 165.44s]  my decades of experience in financial services, including banking, payments, and treasury\n",
      "[165.44s -> 172.10s]  management, tells me I can add tons of value in this role. So when I saw this role combining AI\n",
      "[172.10s -> 178.14s]  innovation with internal financial systems at a company whose mission I believe in, it felt like a\n",
      "[178.14s -> 178.76s]  perfect fit.\n",
      "[178.78s -> 187.08s]  I could not believe an ML partner was there, as if maybe more than 3% of ML community was aware of\n",
      "[187.08s -> 187.56s]  this fact.\n",
      "[187.72s -> 188.70s]  It was world-famous back then.\n",
      "[188.82s -> 193.28s]  And I certainly think might become the most Howard Gould- herzlich honored campus junior\n",
      "[193.28s -> 193.78s]  assistant.\n",
      "[193.92s -> 195.84s]  I think I have experienced a lot better!\n",
      "[196.02s -> 204.52s]  I didÃ©r!\n",
      "[204.86s -> 206.50s]  I was Response!\n",
      "[206.62s -> 207.12s]  Nothing.\n",
      "[207.50s -> 208.20s]  I'm Ã¥ierung!\n",
      "[208.32s -> 208.74s]  I'm Ã¥ring!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Transcribe using local whisper model\n",
    "model = \"local-whisper\"\n",
    "model_size = \"large-v3\"\n",
    "response = local_whisper_transcribe(\n",
    "    file_path=file_path, \n",
    "    model_size=model_size,\n",
    "    device=\"cuda\",\n",
    "    verbose=False, # Set to True for segments printed as they are processed\n",
    "    prompt=\"\",\n",
    "    language=None,\n",
    "    )\n",
    "text:str = response[\"text\"]\n",
    "language:str = response[\"language\"]\n",
    "transcription:any = response[\"transcription\"]\n",
    "duration:float = response[\"inference_time\"]\n",
    "print(f\"duration = {duration:.2f} seconds\")\n",
    "print(f\"{text=}\")\n",
    "print(f\"{language=}\")\n",
    "print(f\"{transcription=}\")\n",
    "print(f\"transcription type: {type(transcription).__name__}\")\n",
    "index=model+\"-\"+model_size+\"-transcription\"\n",
    "runs[index] = text\n",
    "durations[index] = duration\n",
    "\n",
    "# print segments - local models only\n",
    "segments = transcription[\"segments\"]\n",
    "print(f\"segments type: {type(segments).__name__}\")\n",
    "print(\"segments:\")\n",
    "for segment in segments:\n",
    "    print(f\"[{segment[\"start\"]:.2f}s -> {segment[\"end\"]:.2f}s] {segment[\"text\"]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7dfec9e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU cache cleared.\n"
     ]
    }
   ],
   "source": [
    "clear_GPU_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caee06b0",
   "metadata": {},
   "source": [
    "Whisper large-v3-turbo is a finetuned version of a pruned Whisper large-v3 released by OpenAI in October 2024. It's the exact same model as large-v3, except that the number of decoding layers have reduced from 32 to 4. As a result, the model is way faster, at the expense of a minor quality degradation. \n",
    "It's inspired by distil-whisper, but fine-tuned with the same training data as large-v3, excluding translation data. It doesn't support translation well. Whisper in the CLI defaults to turbo.  \n",
    "\n",
    "https://github.com/openai/whisper/discussions/2363\n",
    "\n",
    "https://huggingface.co/openai/whisper-large-v3-turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be4dd681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running whisper model locally. \n",
      "file_path='media/000-why-Stripe.mp3'\n",
      " model_size='turbo'\n",
      " device='cuda'\n",
      " verbose=False\n",
      " prompt=''\n",
      " language=None\n",
      "\n",
      "Detected language: English\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 17911/17911 [00:08<00:00, 2017.30frames/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duration = 9.16 seconds\n",
      "text=\" why stripe well the mission of increasing the gdp of the internet and the key role stripe plays for small companies in particular really resonate with me and here is why the last several years have been all about big tech right particularly the largest players the magnificent seven that's nice because i have some nvidia shares but in the long term that kind of concentration of economic growth is not good for the country or the world this is something patrick and john collison probably agree with because i saw them talking about that in a podcast but i believe that we're entering a new era where ai will enable smaller companies and start-ups to compete more effectively and regain their key role in the economy stripe's role in providing these businesses with trust and access to enterprise grade financial infrastructure will be critical in this new era in other words we need stripe to ensure that the benefits of ai spread across the entire economy not just to the magnificent seven so that's at a high level in terms of the specific role there are a couple of things i love first this position focuses on internal customers in finance accounting and treasury and i am sure some people may strongly prefer having external customers more standard products but you know what throughout my career i've found that the kind of intimacy you can build with internal customers is very special you get to really understand their needs and that can lead to very impactful and long-lasting solutions at pnc for example i developed a custom crm system for the trade finance team that they loved so much they kept using it for 15 years so having internal customers is actually a positive for me second i think ai will drive most of the product innovation in the next 10 years this is going to be true everywhere but particularly in financial services where data plays such a key role i have seen early results of this at amazon where the team used machine learning to build a cash forecasting tool that blew the old tool out of the water and ran in 30 mins instead of eight hours that tool won the adam smith award for best cash flow forecasting solution in 2023 you can check it out and i personally envisioned machine learning tools to detect anomalies in the timing and the content of bank statements coming from banks but this is just scratching the surface on the potential of ml and ai i am so passionate about this possibilities that i quit my job last year to focus on studying ai that passion along with my decades of experience in financial services including banking payments and treasury management tells me i can add tons of value in this role so when i saw this role combining ai innovation with internal financial systems at a company whose mission i believe in it felt like a perfect fit\"\n",
      "language='en'\n",
      "transcription={'text': \" why stripe well the mission of increasing the gdp of the internet and the key role stripe plays for small companies in particular really resonate with me and here is why the last several years have been all about big tech right particularly the largest players the magnificent seven that's nice because i have some nvidia shares but in the long term that kind of concentration of economic growth is not good for the country or the world this is something patrick and john collison probably agree with because i saw them talking about that in a podcast but i believe that we're entering a new era where ai will enable smaller companies and start-ups to compete more effectively and regain their key role in the economy stripe's role in providing these businesses with trust and access to enterprise grade financial infrastructure will be critical in this new era in other words we need stripe to ensure that the benefits of ai spread across the entire economy not just to the magnificent seven so that's at a high level in terms of the specific role there are a couple of things i love first this position focuses on internal customers in finance accounting and treasury and i am sure some people may strongly prefer having external customers more standard products but you know what throughout my career i've found that the kind of intimacy you can build with internal customers is very special you get to really understand their needs and that can lead to very impactful and long-lasting solutions at pnc for example i developed a custom crm system for the trade finance team that they loved so much they kept using it for 15 years so having internal customers is actually a positive for me second i think ai will drive most of the product innovation in the next 10 years this is going to be true everywhere but particularly in financial services where data plays such a key role i have seen early results of this at amazon where the team used machine learning to build a cash forecasting tool that blew the old tool out of the water and ran in 30 mins instead of eight hours that tool won the adam smith award for best cash flow forecasting solution in 2023 you can check it out and i personally envisioned machine learning tools to detect anomalies in the timing and the content of bank statements coming from banks but this is just scratching the surface on the potential of ml and ai i am so passionate about this possibilities that i quit my job last year to focus on studying ai that passion along with my decades of experience in financial services including banking payments and treasury management tells me i can add tons of value in this role so when i saw this role combining ai innovation with internal financial systems at a company whose mission i believe in it felt like a perfect fit\", 'segments': [{'id': 0, 'seek': 0, 'start': 0.0, 'end': 8.68, 'text': ' why stripe well the mission of increasing the gdp of the internet and the key role stripe plays for small companies in particular', 'tokens': [50365, 983, 42957, 731, 264, 4447, 295, 5662, 264, 290, 67, 79, 295, 264, 4705, 293, 264, 2141, 3090, 42957, 5749, 337, 1359, 3431, 294, 1729, 50799], 'temperature': 0.0, 'avg_logprob': -0.3771907872167127, 'compression_ratio': 1.3298969072164948, 'no_speech_prob': 4.5210717114496646e-11}, {'id': 1, 'seek': 868, 'start': 8.68, 'end': 12.059999999999999, 'text': ' really resonate with me and here is why', 'tokens': [50365, 534, 34285, 365, 385, 293, 510, 307, 983, 50534], 'temperature': 0.0, 'avg_logprob': -0.14110169465514436, 'compression_ratio': 1.7113821138211383, 'no_speech_prob': 1.6815624413746288e-12}, {'id': 2, 'seek': 868, 'start': 12.059999999999999, 'end': 27.56, 'text': \" the last several years have been all about big tech right particularly the largest players the magnificent seven that's nice because i have some nvidia shares but in the long term that kind of concentration of economic growth is not good for the country or the world\", 'tokens': [50534, 264, 1036, 2940, 924, 362, 668, 439, 466, 955, 7553, 558, 4098, 264, 6443, 4150, 264, 23690, 3407, 300, 311, 1481, 570, 741, 362, 512, 297, 43021, 12182, 457, 294, 264, 938, 1433, 300, 733, 295, 9856, 295, 4836, 4599, 307, 406, 665, 337, 264, 1941, 420, 264, 1002, 51309], 'temperature': 0.0, 'avg_logprob': -0.14110169465514436, 'compression_ratio': 1.7113821138211383, 'no_speech_prob': 1.6815624413746288e-12}, {'id': 3, 'seek': 868, 'start': 27.56, 'end': 34.14, 'text': ' this is something patrick and john collison probably agree with because i saw them talking about that in a podcast', 'tokens': [51309, 341, 307, 746, 1947, 9323, 293, 35097, 1263, 2770, 1391, 3986, 365, 570, 741, 1866, 552, 1417, 466, 300, 294, 257, 7367, 51638], 'temperature': 0.0, 'avg_logprob': -0.14110169465514436, 'compression_ratio': 1.7113821138211383, 'no_speech_prob': 1.6815624413746288e-12}, {'id': 4, 'seek': 3414, 'start': 34.14, 'end': 44.82, 'text': \" but i believe that we're entering a new era where ai will enable smaller companies and start-ups to compete more effectively and regain their key role in the economy\", 'tokens': [50365, 457, 741, 1697, 300, 321, 434, 11104, 257, 777, 4249, 689, 9783, 486, 9528, 4356, 3431, 293, 722, 12, 7528, 281, 11831, 544, 8659, 293, 35336, 641, 2141, 3090, 294, 264, 5010, 50899], 'temperature': 0.0, 'avg_logprob': -0.1518606098218896, 'compression_ratio': 1.7391304347826086, 'no_speech_prob': 3.559691820823052e-12}, {'id': 5, 'seek': 3414, 'start': 44.82, 'end': 53.82, 'text': \" stripe's role in providing these businesses with trust and access to enterprise grade financial infrastructure will be critical in this new era\", 'tokens': [50899, 42957, 311, 3090, 294, 6530, 613, 6011, 365, 3361, 293, 2105, 281, 14132, 7204, 4669, 6896, 486, 312, 4924, 294, 341, 777, 4249, 51349], 'temperature': 0.0, 'avg_logprob': -0.1518606098218896, 'compression_ratio': 1.7391304347826086, 'no_speech_prob': 3.559691820823052e-12}, {'id': 6, 'seek': 3414, 'start': 53.82, 'end': 62.46, 'text': ' in other words we need stripe to ensure that the benefits of ai spread across the entire economy not just to the magnificent seven', 'tokens': [51349, 294, 661, 2283, 321, 643, 42957, 281, 5586, 300, 264, 5311, 295, 9783, 3974, 2108, 264, 2302, 5010, 406, 445, 281, 264, 23690, 3407, 51781], 'temperature': 0.0, 'avg_logprob': -0.1518606098218896, 'compression_ratio': 1.7391304347826086, 'no_speech_prob': 3.559691820823052e-12}, {'id': 7, 'seek': 6246, 'start': 62.46, 'end': 64.14, 'text': \" so that's at a high level\", 'tokens': [50365, 370, 300, 311, 412, 257, 1090, 1496, 50449], 'temperature': 0.0, 'avg_logprob': -0.10378500393458776, 'compression_ratio': 1.7434782608695651, 'no_speech_prob': 4.311134782497561e-12}, {'id': 8, 'seek': 6246, 'start': 64.14, 'end': 68.3, 'text': ' in terms of the specific role there are a couple of things i love', 'tokens': [50449, 294, 2115, 295, 264, 2685, 3090, 456, 366, 257, 1916, 295, 721, 741, 959, 50657], 'temperature': 0.0, 'avg_logprob': -0.10378500393458776, 'compression_ratio': 1.7434782608695651, 'no_speech_prob': 4.311134782497561e-12}, {'id': 9, 'seek': 6246, 'start': 68.3, 'end': 74.02, 'text': ' first this position focuses on internal customers in finance accounting and treasury', 'tokens': [50657, 700, 341, 2535, 16109, 322, 6920, 4581, 294, 10719, 19163, 293, 47213, 50943], 'temperature': 0.0, 'avg_logprob': -0.10378500393458776, 'compression_ratio': 1.7434782608695651, 'no_speech_prob': 4.311134782497561e-12}, {'id': 10, 'seek': 6246, 'start': 74.02, 'end': 79.74000000000001, 'text': ' and i am sure some people may strongly prefer having external customers more standard products', 'tokens': [50943, 293, 741, 669, 988, 512, 561, 815, 10613, 4382, 1419, 8320, 4581, 544, 3832, 3383, 51229], 'temperature': 0.0, 'avg_logprob': -0.10378500393458776, 'compression_ratio': 1.7434782608695651, 'no_speech_prob': 4.311134782497561e-12}, {'id': 11, 'seek': 6246, 'start': 79.74000000000001, 'end': 87.44, 'text': \" but you know what throughout my career i've found that the kind of intimacy you can build with internal customers is very special\", 'tokens': [51229, 457, 291, 458, 437, 3710, 452, 3988, 741, 600, 1352, 300, 264, 733, 295, 34450, 291, 393, 1322, 365, 6920, 4581, 307, 588, 2121, 51614], 'temperature': 0.0, 'avg_logprob': -0.10378500393458776, 'compression_ratio': 1.7434782608695651, 'no_speech_prob': 4.311134782497561e-12}, {'id': 12, 'seek': 8744, 'start': 87.44, 'end': 94.0, 'text': ' you get to really understand their needs and that can lead to very impactful and long-lasting solutions', 'tokens': [50365, 291, 483, 281, 534, 1223, 641, 2203, 293, 300, 393, 1477, 281, 588, 30842, 293, 938, 12, 29346, 6547, 50693], 'temperature': 0.0, 'avg_logprob': -0.0647335501278148, 'compression_ratio': 1.6462882096069869, 'no_speech_prob': 3.0930707214243958e-12}, {'id': 13, 'seek': 8744, 'start': 94.0, 'end': 100.32, 'text': ' at pnc for example i developed a custom crm system for the trade finance team that they loved so much', 'tokens': [50693, 412, 280, 77, 66, 337, 1365, 741, 4743, 257, 2375, 941, 76, 1185, 337, 264, 4923, 10719, 1469, 300, 436, 4333, 370, 709, 51009], 'temperature': 0.0, 'avg_logprob': -0.0647335501278148, 'compression_ratio': 1.6462882096069869, 'no_speech_prob': 3.0930707214243958e-12}, {'id': 14, 'seek': 8744, 'start': 100.32, 'end': 106.4, 'text': ' they kept using it for 15 years so having internal customers is actually a positive for me', 'tokens': [51009, 436, 4305, 1228, 309, 337, 2119, 924, 370, 1419, 6920, 4581, 307, 767, 257, 3353, 337, 385, 51313], 'temperature': 0.0, 'avg_logprob': -0.0647335501278148, 'compression_ratio': 1.6462882096069869, 'no_speech_prob': 3.0930707214243958e-12}, {'id': 15, 'seek': 8744, 'start': 106.4, 'end': 111.75999999999999, 'text': ' second i think ai will drive most of the product innovation in the next 10 years', 'tokens': [51313, 1150, 741, 519, 9783, 486, 3332, 881, 295, 264, 1674, 8504, 294, 264, 958, 1266, 924, 51581], 'temperature': 0.0, 'avg_logprob': -0.0647335501278148, 'compression_ratio': 1.6462882096069869, 'no_speech_prob': 3.0930707214243958e-12}, {'id': 16, 'seek': 11176, 'start': 111.76, 'end': 118.56, 'text': ' this is going to be true everywhere but particularly in financial services where data plays such a key', 'tokens': [50365, 341, 307, 516, 281, 312, 2074, 5315, 457, 4098, 294, 4669, 3328, 689, 1412, 5749, 1270, 257, 2141, 50705], 'temperature': 0.0, 'avg_logprob': -0.10376097646991858, 'compression_ratio': 1.6748971193415638, 'no_speech_prob': 2.676881936600206e-12}, {'id': 17, 'seek': 11176, 'start': 118.56, 'end': 124.88000000000001, 'text': ' role i have seen early results of this at amazon where the team used machine learning to build a', 'tokens': [50705, 3090, 741, 362, 1612, 2440, 3542, 295, 341, 412, 47010, 689, 264, 1469, 1143, 3479, 2539, 281, 1322, 257, 51021], 'temperature': 0.0, 'avg_logprob': -0.10376097646991858, 'compression_ratio': 1.6748971193415638, 'no_speech_prob': 2.676881936600206e-12}, {'id': 18, 'seek': 11176, 'start': 124.88000000000001, 'end': 131.28, 'text': ' cash forecasting tool that blew the old tool out of the water and ran in 30 mins instead of eight hours', 'tokens': [51021, 6388, 44331, 2290, 300, 19075, 264, 1331, 2290, 484, 295, 264, 1281, 293, 5872, 294, 2217, 31539, 2602, 295, 3180, 2496, 51341], 'temperature': 0.0, 'avg_logprob': -0.10376097646991858, 'compression_ratio': 1.6748971193415638, 'no_speech_prob': 2.676881936600206e-12}, {'id': 19, 'seek': 11176, 'start': 132.4, 'end': 139.76, 'text': ' that tool won the adam smith award for best cash flow forecasting solution in 2023 you can check it out', 'tokens': [51397, 300, 2290, 1582, 264, 16368, 899, 355, 7130, 337, 1151, 6388, 3095, 44331, 3827, 294, 44377, 291, 393, 1520, 309, 484, 51765], 'temperature': 0.0, 'avg_logprob': -0.10376097646991858, 'compression_ratio': 1.6748971193415638, 'no_speech_prob': 2.676881936600206e-12}, {'id': 20, 'seek': 13976, 'start': 139.76, 'end': 145.67999999999998, 'text': ' and i personally envisioned machine learning tools to detect anomalies in the timing and the content of', 'tokens': [50365, 293, 741, 5665, 47733, 3479, 2539, 3873, 281, 5531, 24769, 48872, 294, 264, 10822, 293, 264, 2701, 295, 50661], 'temperature': 0.0, 'avg_logprob': -0.049400915582496, 'compression_ratio': 1.7246963562753037, 'no_speech_prob': 2.8381398793630996e-12}, {'id': 21, 'seek': 13976, 'start': 145.67999999999998, 'end': 152.95999999999998, 'text': ' bank statements coming from banks but this is just scratching the surface on the potential of ml and ai i am', 'tokens': [50661, 3765, 12363, 1348, 490, 10237, 457, 341, 307, 445, 29699, 264, 3753, 322, 264, 3995, 295, 23271, 293, 9783, 741, 669, 51025], 'temperature': 0.0, 'avg_logprob': -0.049400915582496, 'compression_ratio': 1.7246963562753037, 'no_speech_prob': 2.8381398793630996e-12}, {'id': 22, 'seek': 13976, 'start': 152.95999999999998, 'end': 159.92, 'text': ' so passionate about this possibilities that i quit my job last year to focus on studying ai that passion', 'tokens': [51025, 370, 11410, 466, 341, 12178, 300, 741, 10366, 452, 1691, 1036, 1064, 281, 1879, 322, 7601, 9783, 300, 5418, 51373], 'temperature': 0.0, 'avg_logprob': -0.049400915582496, 'compression_ratio': 1.7246963562753037, 'no_speech_prob': 2.8381398793630996e-12}, {'id': 23, 'seek': 13976, 'start': 159.92, 'end': 166.32, 'text': ' along with my decades of experience in financial services including banking payments and treasury management', 'tokens': [51373, 2051, 365, 452, 7878, 295, 1752, 294, 4669, 3328, 3009, 18261, 14348, 293, 47213, 4592, 51693], 'temperature': 0.0, 'avg_logprob': -0.049400915582496, 'compression_ratio': 1.7246963562753037, 'no_speech_prob': 2.8381398793630996e-12}, {'id': 24, 'seek': 16632, 'start': 166.32, 'end': 173.28, 'text': ' tells me i can add tons of value in this role so when i saw this role combining ai innovation with', 'tokens': [50365, 5112, 385, 741, 393, 909, 9131, 295, 2158, 294, 341, 3090, 370, 562, 741, 1866, 341, 3090, 21928, 9783, 8504, 365, 50713], 'temperature': 0.0, 'avg_logprob': -0.12274811988653139, 'compression_ratio': 1.4883720930232558, 'no_speech_prob': 5.642822147045035e-12}, {'id': 25, 'seek': 16632, 'start': 173.28, 'end': 187.76, 'text': ' internal financial systems at a company whose mission i believe in it felt like a perfect fit', 'tokens': [50713, 6920, 4669, 3652, 412, 257, 2237, 6104, 4447, 741, 1697, 294, 309, 2762, 411, 257, 2176, 3318, 51437], 'temperature': 0.0, 'avg_logprob': -0.12274811988653139, 'compression_ratio': 1.4883720930232558, 'no_speech_prob': 5.642822147045035e-12}], 'language': 'en'}\n",
      "transcription type: dict\n",
      "segments type: list\n",
      "segments:\n",
      "[0.00s -> 8.68s]  why stripe well the mission of increasing the gdp of the internet and the key role stripe plays for small companies in particular\n",
      "[8.68s -> 12.06s]  really resonate with me and here is why\n",
      "[12.06s -> 27.56s]  the last several years have been all about big tech right particularly the largest players the magnificent seven that's nice because i have some nvidia shares but in the long term that kind of concentration of economic growth is not good for the country or the world\n",
      "[27.56s -> 34.14s]  this is something patrick and john collison probably agree with because i saw them talking about that in a podcast\n",
      "[34.14s -> 44.82s]  but i believe that we're entering a new era where ai will enable smaller companies and start-ups to compete more effectively and regain their key role in the economy\n",
      "[44.82s -> 53.82s]  stripe's role in providing these businesses with trust and access to enterprise grade financial infrastructure will be critical in this new era\n",
      "[53.82s -> 62.46s]  in other words we need stripe to ensure that the benefits of ai spread across the entire economy not just to the magnificent seven\n",
      "[62.46s -> 64.14s]  so that's at a high level\n",
      "[64.14s -> 68.30s]  in terms of the specific role there are a couple of things i love\n",
      "[68.30s -> 74.02s]  first this position focuses on internal customers in finance accounting and treasury\n",
      "[74.02s -> 79.74s]  and i am sure some people may strongly prefer having external customers more standard products\n",
      "[79.74s -> 87.44s]  but you know what throughout my career i've found that the kind of intimacy you can build with internal customers is very special\n",
      "[87.44s -> 94.00s]  you get to really understand their needs and that can lead to very impactful and long-lasting solutions\n",
      "[94.00s -> 100.32s]  at pnc for example i developed a custom crm system for the trade finance team that they loved so much\n",
      "[100.32s -> 106.40s]  they kept using it for 15 years so having internal customers is actually a positive for me\n",
      "[106.40s -> 111.76s]  second i think ai will drive most of the product innovation in the next 10 years\n",
      "[111.76s -> 118.56s]  this is going to be true everywhere but particularly in financial services where data plays such a key\n",
      "[118.56s -> 124.88s]  role i have seen early results of this at amazon where the team used machine learning to build a\n",
      "[124.88s -> 131.28s]  cash forecasting tool that blew the old tool out of the water and ran in 30 mins instead of eight hours\n",
      "[132.40s -> 139.76s]  that tool won the adam smith award for best cash flow forecasting solution in 2023 you can check it out\n",
      "[139.76s -> 145.68s]  and i personally envisioned machine learning tools to detect anomalies in the timing and the content of\n",
      "[145.68s -> 152.96s]  bank statements coming from banks but this is just scratching the surface on the potential of ml and ai i am\n",
      "[152.96s -> 159.92s]  so passionate about this possibilities that i quit my job last year to focus on studying ai that passion\n",
      "[159.92s -> 166.32s]  along with my decades of experience in financial services including banking payments and treasury management\n",
      "[166.32s -> 173.28s]  tells me i can add tons of value in this role so when i saw this role combining ai innovation with\n",
      "[173.28s -> 187.76s]  internal financial systems at a company whose mission i believe in it felt like a perfect fit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Transcribe using local whisper model\n",
    "model = \"local-whisper\"\n",
    "model_size = \"turbo\"  # large-v3-turbo is the same\n",
    "response = local_whisper_transcribe(\n",
    "    file_path=file_path, \n",
    "    model_size=model_size,\n",
    "    device=\"cuda\",\n",
    "    verbose=False, # Set to True for segments printed as they are processed\n",
    "    prompt=\"\",\n",
    "    language=None,\n",
    "    )\n",
    "text:str = response[\"text\"]\n",
    "language:str = response[\"language\"]\n",
    "transcription:any = response[\"transcription\"]\n",
    "duration:float = response[\"inference_time\"]\n",
    "print(f\"duration = {duration:.2f} seconds\")\n",
    "print(f\"{text=}\")\n",
    "print(f\"{language=}\")\n",
    "print(f\"{transcription=}\")\n",
    "print(f\"transcription type: {type(transcription).__name__}\")\n",
    "index=model+\"-\"+model_size+\"-transcription\"\n",
    "runs[index] = text\n",
    "durations[index] = duration\n",
    "\n",
    "# print segments - local models only\n",
    "segments = transcription[\"segments\"]\n",
    "print(f\"segments type: {type(segments).__name__}\")\n",
    "print(\"segments:\")\n",
    "for segment in segments:\n",
    "    print(f\"[{segment[\"start\"]:.2f}s -> {segment[\"end\"]:.2f}s] {segment[\"text\"]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe0014b",
   "metadata": {},
   "source": [
    "**Local Whisper Ouput:**\n",
    "\n",
    "The output for the local whisper model is different from the OpenAI whisper API. The local model doesn't use OpenAI custom objects (e.g. transcription, TranscriptionVerbose). The transcribe function of the local whisper model outputs a dictionary containing:\n",
    "* the resulting text (\"text\") \n",
    "* segment-level details (\"segments\")\n",
    "* the spoken language (\"language\"), which is detected when `decode_options[\"language\"]` is None.\n",
    "\n",
    "**Segments:**\n",
    "\n",
    "Even though the initial audio is split in 30 second chunks, the final segments are not necessarily 30 seconds long, and it's the model that determines where they start by generating special tokens as their next prediction.\n",
    "\n",
    "The key difference between the segments initially produced by `whisper.pad_or_trim` and the segments returned by the final `transcribe` function is:\n",
    "\n",
    "* **Initial segments (`whisper.pad_or_trim`)** are fixed-size (exactly 30 seconds or padded/truncated to fit that length). These segments are just a raw preprocessing step to feed the encoder a standard-length input.\n",
    "\n",
    "* **Final segments (`transcribe` function outputs)** represent logically coherent segments of transcribed text, which have precise timestamps based on actual detected speech boundaries and may be shorter or differently sized based on the decoderâs output and silence detection.\n",
    "\n",
    "* **1. Initial segments (`whisper.pad_or_trim`)**:\n",
    "\n",
    "  * **Fixed-length segments**:\n",
    "\n",
    "    * Always exactly 30 seconds (padded with silence if shorter, truncated if longer).\n",
    "    * Ensures uniform size for encoder input.\n",
    "\n",
    "  * **Purpose**:\n",
    "\n",
    "    * **Standardizing inputs** to the model for consistent processing.\n",
    "    * The encoder always receives inputs of shape `(80 mel bands Ã 1500 time-steps)`.\n",
    "\n",
    "  * **No meaning attached to boundaries**:\n",
    "\n",
    "    * Initial boundaries do not reflect speech or silence; they're purely based on a fixed time slice.\n",
    "\n",
    "  * Example code: `mel_segment = whisper.pad_or_trim(mel, N_FRAMES)`\n",
    "\n",
    "* **2. Final segments (`transcribe` function output)**:\n",
    "\n",
    "  * **Variable-length segments**:\n",
    "\n",
    "    * Boundaries determined by decoder output.\n",
    "    * Start and end times correspond to actual detected speech segments and may vary significantly from exactly 30-second intervals.\n",
    "\n",
    "  * **Purpose**:\n",
    "\n",
    "    * Reflect natural speech pauses and linguistic coherence.\n",
    "    * Provide meaningful, human-readable timestamps for text segments.\n",
    "\n",
    "  * **Features**:\n",
    "\n",
    "    * Each segment contains:\n",
    "\n",
    "      * **Text**: actual decoded text.\n",
    "      * **Timestamps**: precise start/end points relative to the original audio.\n",
    "      * Metadata like tokens, average log-probability, and no-speech probability.\n",
    "\n",
    "Example output from `transcribe()`:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"text\":\"Hello, this is Whisper. Let's test transcription.\",\n",
    "  \"segments\": [\n",
    "    {\n",
    "      \"id\": 0,\n",
    "      \"seek\": 0,\n",
    "      \"start\": 0.0,\n",
    "      \"end\": 5.62,\n",
    "      \"text\": \"Hello, this is Whisper.\",\n",
    "      ...\n",
    "    },\n",
    "    {\n",
    "      \"id\": 1,\n",
    "      \"seek\": 281,\n",
    "      \"start\": 5.62,\n",
    "      \"end\": 11.30,\n",
    "      \"text\": \"Let's test transcription.\",\n",
    "      ...\n",
    "    }\n",
    "  ],\n",
    "  \"language\": \"en\"\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Summary Table:**\n",
    "\n",
    "| Aspect                | Initial segments (`pad_or_trim`) | Final segments (`transcribe`)      |\n",
    "| --------------------- | -------------------------------- | ---------------------------------- |\n",
    "| **Length**            | Fixed (30 seconds exactly)       | Variable, depending on speech      |\n",
    "| **Purpose**           | Encoder input standardization    | Meaningful transcription output    |\n",
    "| **Content**           | Raw Mel spectrogram segments     | Decoded textual segments           |\n",
    "| **Timestamp meaning** | Arbitrary/fixed intervals        | Meaningful speech-based timestamps |\n",
    "| **Generated by**      | Preprocessing (encoder stage)    | Decoder logic (output stage)       |\n",
    "\n",
    "---\n",
    "\n",
    "**Why the Difference?**\n",
    "\n",
    "* **Initial segments** standardize model input to simplify computation.\n",
    "* **Final segments** represent meaningful linguistic output, shaped by the decoder's speech detection and language modeling.\n",
    "\n",
    "Thus, the difference arises from the modelâs transition from fixed-size encoder inputs to semantically coherent, decoder-generated outputs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284f917d",
   "metadata": {},
   "source": [
    "### Transcription using Faster whisper\n",
    "\n",
    "https://github.com/SYSTRAN/faster-whisper\n",
    "\n",
    "**Faster-Whisper** is a high-performance, optimized implementation of OpenAIâs Whisper speech recognition model, built on top of **CTranslate2**âan efficient inference engine for transformer models.\n",
    "\n",
    "While the original Whisper is implemented in PyTorch and designed primarily for flexibility and research, Faster-Whisper focuses on **speed and low memory usage**, making it suitable for real-time transcription and deployment on CPUs or limited GPUs.\n",
    "\n",
    "**CTranslate2** is a C++ and Python-compatible inference engine that converts transformer models (e.g., from PyTorch or TensorFlow) into a format optimized for fast execution. It supports features like quantization (e.g., int8), multi-threading, and device-agnostic execution (CPU, GPU, Apple Silicon), enabling models like Whisper to run faster with reduced resource requirements.\n",
    "\n",
    "In short:\n",
    "\n",
    "* **Whisper** = accurate, full-feature ASR model in PyTorch.\n",
    "* **Faster-Whisper** = same model, recompiled for speed using CTranslate2.\n",
    "* **CTranslate2** = the engine that makes this optimization possible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42237592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU cache cleared.\n"
     ]
    }
   ],
   "source": [
    "clear_GPU_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5469a063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running faster whisper model locally. \n",
      "file_path='media/000-why-Stripe.mp3'\n",
      " model_size='large-v3'\n",
      " device='cuda'\n",
      " compute_type='float16'\n",
      " language=None\n",
      " prompt=None\n",
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Transcribe using local faster whisper model\n",
    "model = \"local-faster-whisper\"\n",
    "model_size = \"large-v3\"\n",
    "response = local_faster_whisper_transcribe(\n",
    "    file_path=file_path, \n",
    "    model_size=model_size,\n",
    "    device=\"cuda\",\n",
    "    )\n",
    "text:str = response[\"text\"]\n",
    "language:str = response[\"language\"]\n",
    "transcription:any = response[\"transcription\"]\n",
    "duration:float = response[\"inference_time\"]\n",
    "print(f\"duration = {duration:.2f} seconds\")\n",
    "print(f\"{text=}\")\n",
    "print(f\"{language=}\")\n",
    "print(f\"{transcription=}\")\n",
    "print(f\"transcription type: {type(transcription).__name__}\")\n",
    "index=model+\"-\"+model_size+\"-transcription\"\n",
    "runs[index] = text\n",
    "durations[index] = duration\n",
    "\n",
    "# print segments - local models only\n",
    "segments = transcription[\"segments\"]\n",
    "print(f\"segments type: {type(segments).__name__}\")\n",
    "print(\"segments:\")\n",
    "for segment in segments:\n",
    "    print(f\"[{segment[\"start\"]:.2f}s -> {segment[\"end\"]:.2f}s] {segment[\"text\"]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2655a1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_GPU_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c4a3e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running faster whisper model locally. \n",
      "file_path='media/000-why-Stripe.mp3'\n",
      " model_size='distil-large-v3'\n",
      " device='cuda'\n",
      " compute_type='float16'\n",
      " language=None\n",
      " prompt=None\n",
      "\n",
      "Detected language en with probability 0.9990234375\n",
      "duration = 3.92 seconds\n",
      "text=\" Why Stripe? Well, the mission of increasing the GDP of the Internet and the key role Stripe plays for small companies in particular really resonate with me, and here is why. The last several years have been all about big tech, right? Particularly the largest players, the Magnificent Seven. That's nice because I have some Nvidia shares, but in the long term, that kind of concentration of economic growth is not good for the country or the world. This is something Patrick and John Collison probably agree with because I saw them talking about that in a podcast. But I believe that we're entering a new era where AI will enable smaller companies and startups to compete more effectively and regain their key role in the economy. Stripe's role in providing these businesses with trust and access to enterprise-grade financial infrastructure will be critical in this new era. In other words, we need Stripe to ensure that the benefits of AI spread across the entire economy, not just to the magnificent 7. So that's at a high level. In terms of the specific role, there are a couple of things I love. First, this position focuses on internal customers in finance, accounting, and treasury. And I am sure some people may strongly prefer having external customers, more standard products. But you know what? Throughout my career, I've found that the kind of intimacy you can build with internal customers is very special. You get to really understand their needs and that can lead to very impactful and long-lasting solutions. At PNC, for example, I developed a custom CRM system for the trade finance team that they loved so much. They kept using it for 15 years. So having internal customers is actually a positive for me. Second, I think AI will drive most of the product innovation in the next 10 years. This is going to be true everywhere, but particularly in financial services, where data plays such a key role. I have seen early results of this at Amazon, where the team used machine learning to build a cash forecasting tool that blew the old tool out of the water, and ran in 30 minns instead of eight hours. That tool won the Adam Smith Award for Best Cash Flow Forecasting Solution in 2023. You can check it out. And I personally envisioned machine learning tools to detect anomalies in the timing and the content of bank statements coming from banks. But this is just scratching the surface on the potential of ML and AI. I am so passionate about this possibilities that I quit my job last year to focus on studying AI. That passion, along with my decades of experience in financial services, including banking, payments, and treasury management, tells me I can add tons of value in this role. So when I saw this role combining AI innovation with internal financial systems at a company whose mission I believe in, it felt like a perfect fit.\"\n",
      "language='en'\n",
      "transcription={'segments': [{'start': 0.0, 'end': 0.78, 'text': ' Why Stripe?'}, {'start': 1.4000000000000001, 'end': 4.48, 'text': ' Well, the mission of increasing the GDP of the Internet'}, {'start': 4.48, 'end': 8.24, 'text': ' and the key role Stripe plays for small companies in particular'}, {'start': 8.24, 'end': 11.1, 'text': ' really resonate with me, and here is why.'}, {'start': 12.0, 'end': 15.3, 'text': ' The last several years have been all about big tech, right?'}, {'start': 15.46, 'end': 18.18, 'text': ' Particularly the largest players, the Magnificent Seven.'}, {'start': 18.580000000000002, 'end': 20.8, 'text': \" That's nice because I have some Nvidia shares,\"}, {'start': 21.16, 'end': 24.66, 'text': ' but in the long term, that kind of concentration of economic growth'}, {'start': 24.66, 'end': 27.04, 'text': ' is not good for the country or the world.'}, {'start': 27.04, 'end': 30.84, 'text': ' This is something Patrick and John Collison probably agree with'}, {'start': 30.84, 'end': 33.14, 'text': ' because I saw them talking about that in a podcast.'}, {'start': 34.06, 'end': 36.28, 'text': \" But I believe that we're entering a new era\"}, {'start': 36.28, 'end': 40.0, 'text': ' where AI will enable smaller companies and startups'}, {'start': 40.0, 'end': 41.8, 'text': ' to compete more effectively'}, {'start': 41.8, 'end': 44.64, 'text': ' and regain their key role in the economy.'}, {'start': 45.58, 'end': 47.7, 'text': \" Stripe's role in providing these businesses\"}, {'start': 47.7, 'end': 51.6, 'text': ' with trust and access to enterprise-grade financial infrastructure'}, {'start': 51.6, 'end': 53.7, 'text': ' will be critical in this new era.'}, {'start': 54.34, 'end': 56.980000000000004, 'text': ' In other words, we need Stripe to ensure that'}, {'start': 57.04, 'end': 63.04, 'text': ' the benefits of AI spread across the entire economy, not just to the magnificent 7.'}, {'start': 63.04, 'end': 65.28, 'text': \" So that's at a high level.\"}, {'start': 65.28, 'end': 68.8, 'text': ' In terms of the specific role, there are a couple of things I love.'}, {'start': 68.8, 'end': 75.03999999999999, 'text': ' First, this position focuses on internal customers in finance, accounting, and treasury.'}, {'start': 75.03999999999999, 'end': 80.4, 'text': ' And I am sure some people may strongly prefer having external customers, more standard products.'}, {'start': 80.4, 'end': 85.34, 'text': \" But you know what? Throughout my career, I've found that the kind of intimacy you can build with\"}, {'start': 85.34, 'end': 90.54, 'text': ' internal customers is very special. You get to really understand their needs and that'}, {'start': 90.54, 'end': 97.18, 'text': ' can lead to very impactful and long-lasting solutions. At PNC, for example, I developed a custom'}, {'start': 97.18, 'end': 103.34, 'text': ' CRM system for the trade finance team that they loved so much. They kept using it for 15 years.'}, {'start': 103.34, 'end': 109.74000000000001, 'text': ' So having internal customers is actually a positive for me. Second, I think AI will drive most of the'}, {'start': 109.74000000000001, 'end': 115.32000000000001, 'text': ' product innovation in the next 10 years. This is going to be true everywhere, but particularly'}, {'start': 115.34, 'end': 118.94, 'text': ' in financial services, where data plays such a key role.'}, {'start': 119.9, 'end': 124.98, 'text': ' I have seen early results of this at Amazon, where the team used machine learning to build a'}, {'start': 124.98, 'end': 130.82, 'text': ' cash forecasting tool that blew the old tool out of the water, and ran in 30 minns instead of'}, {'start': 130.82, 'end': 137.38, 'text': ' eight hours. That tool won the Adam Smith Award for Best Cash Flow Forecasting Solution in'}, {'start': 137.38, 'end': 144.26, 'text': ' 2023. You can check it out. And I personally envisioned machine learning tools to detect anomalies in the'}, {'start': 144.26, 'end': 149.56, 'text': ' timing and the content of bank statements coming from banks. But this is just scratching'}, {'start': 149.56, 'end': 155.62, 'text': ' the surface on the potential of ML and AI. I am so passionate about this possibilities that I quit my'}, {'start': 155.62, 'end': 162.48, 'text': ' job last year to focus on studying AI. That passion, along with my decades of experience in financial'}, {'start': 162.48, 'end': 168.26, 'text': ' services, including banking, payments, and treasury management, tells me I can add tons of value'}, {'start': 168.26, 'end': 174.14, 'text': ' in this role. So when I saw this role combining AI innovation with internal financial'}, {'start': 174.14000000000001, 'end': 178.9, 'text': ' systems at a company whose mission I believe in, it felt like a perfect fit.'}], 'info': TranscriptionInfo(language='en', language_probability=0.9990234375, duration=179.112, duration_after_vad=179.112, all_language_probs=[('en', 0.9990234375), ('es', 0.0001970529556274414), ('zh', 9.60230827331543e-05), ('ja', 8.744001388549805e-05), ('fr', 7.712841033935547e-05), ('de', 6.395578384399414e-05), ('ru', 5.823373794555664e-05), ('pt', 4.8279762268066406e-05), ('nn', 4.5359134674072266e-05), ('it', 4.392862319946289e-05), ('vi', 3.534555435180664e-05), ('ko', 3.11732292175293e-05), ('cy', 2.586841583251953e-05), ('la', 2.282857894897461e-05), ('nl', 2.014636993408203e-05), ('tl', 1.8298625946044922e-05), ('sv', 1.8298625946044922e-05), ('tr', 1.4722347259521484e-05), ('id', 1.4722347259521484e-05), ('th', 1.4722347259521484e-05), ('km', 1.2576580047607422e-05), ('pl', 1.043081283569336e-05), ('jw', 8.404254913330078e-06), ('ms', 7.62939453125e-06), ('hi', 7.3909759521484375e-06), ('ar', 7.152557373046875e-06), ('ro', 6.556510925292969e-06), ('el', 6.139278411865234e-06), ('hu', 3.814697265625e-06), ('da', 3.635883331298828e-06), ('fi', 3.159046173095703e-06), ('haw', 3.159046173095703e-06), ('no', 2.9206275939941406e-06), ('si', 2.7418136596679688e-06), ('cs', 2.6226043701171875e-06), ('sn', 2.6226043701171875e-06), ('fa', 2.1457672119140625e-06), ('sl', 2.0265579223632812e-06), ('sw', 1.7285346984863281e-06), ('mi', 1.6093254089355469e-06), ('ur', 1.430511474609375e-06), ('hr', 1.430511474609375e-06), ('uk', 1.3113021850585938e-06), ('he', 1.0728836059570312e-06), ('br', 8.940696716308594e-07), ('ta', 8.344650268554688e-07), ('te', 8.344650268554688e-07), ('ml', 7.152557373046875e-07), ('bn', 5.960464477539062e-07), ('sk', 4.76837158203125e-07), ('ca', 4.172325134277344e-07), ('sa', 4.172325134277344e-07), ('bg', 3.5762786865234375e-07), ('lt', 3.5762786865234375e-07), ('yo', 2.980232238769531e-07), ('lv', 2.980232238769531e-07), ('yue', 2.384185791015625e-07), ('is', 1.7881393432617188e-07), ('hy', 1.7881393432617188e-07), ('ne', 1.1920928955078125e-07), ('bs', 1.1920928955078125e-07), ('sq', 1.1920928955078125e-07), ('gl', 1.1920928955078125e-07), ('af', 1.1920928955078125e-07), ('ht', 1.1920928955078125e-07), ('eu', 5.960464477539063e-08), ('mn', 5.960464477539063e-08), ('kk', 5.960464477539063e-08), ('mr', 5.960464477539063e-08), ('pa', 5.960464477539063e-08), ('et', 5.960464477539063e-08), ('az', 5.960464477539063e-08), ('my', 5.960464477539063e-08), ('yi', 5.960464477539063e-08), ('lo', 5.960464477539063e-08), ('fo', 5.960464477539063e-08), ('sr', 5.960464477539063e-08), ('bo', 5.960464477539063e-08), ('uz', 0.0), ('be', 0.0), ('ka', 0.0), ('ps', 0.0), ('tk', 0.0), ('sd', 0.0), ('mt', 0.0), ('oc', 0.0), ('lb', 0.0), ('so', 0.0), ('gu', 0.0), ('kn', 0.0), ('mg', 0.0), ('as', 0.0), ('tt', 0.0), ('tg', 0.0), ('ln', 0.0), ('ha', 0.0), ('ba', 0.0), ('mk', 0.0), ('su', 0.0), ('am', 0.0)], transcription_options=TranscriptionOptions(beam_size=5, best_of=5, patience=1, length_penalty=1, repetition_penalty=1, no_repeat_ngram_size=0, log_prob_threshold=-1.0, no_speech_threshold=0.6, compression_ratio_threshold=2.4, condition_on_previous_text=True, prompt_reset_on_temperature=0.5, temperatures=[0.0, 0.2, 0.4, 0.6, 0.8, 1.0], initial_prompt=None, prefix=None, suppress_blank=True, suppress_tokens=[-1], without_timestamps=False, max_initial_timestamp=1.0, word_timestamps=False, prepend_punctuations='\"\\'âÂ¿([{-', append_punctuations='\"\\'.ã,ï¼!ï¼?ï¼:ï¼â)]}ã', max_new_tokens=None, clip_timestamps='0', hallucination_silence_threshold=None, hotwords=None), vad_options=None)}\n",
      "transcription type: dict\n",
      "segments type: list\n",
      "segments:\n",
      "[0.00s -> 0.78s]  Why Stripe?\n",
      "[1.40s -> 4.48s]  Well, the mission of increasing the GDP of the Internet\n",
      "[4.48s -> 8.24s]  and the key role Stripe plays for small companies in particular\n",
      "[8.24s -> 11.10s]  really resonate with me, and here is why.\n",
      "[12.00s -> 15.30s]  The last several years have been all about big tech, right?\n",
      "[15.46s -> 18.18s]  Particularly the largest players, the Magnificent Seven.\n",
      "[18.58s -> 20.80s]  That's nice because I have some Nvidia shares,\n",
      "[21.16s -> 24.66s]  but in the long term, that kind of concentration of economic growth\n",
      "[24.66s -> 27.04s]  is not good for the country or the world.\n",
      "[27.04s -> 30.84s]  This is something Patrick and John Collison probably agree with\n",
      "[30.84s -> 33.14s]  because I saw them talking about that in a podcast.\n",
      "[34.06s -> 36.28s]  But I believe that we're entering a new era\n",
      "[36.28s -> 40.00s]  where AI will enable smaller companies and startups\n",
      "[40.00s -> 41.80s]  to compete more effectively\n",
      "[41.80s -> 44.64s]  and regain their key role in the economy.\n",
      "[45.58s -> 47.70s]  Stripe's role in providing these businesses\n",
      "[47.70s -> 51.60s]  with trust and access to enterprise-grade financial infrastructure\n",
      "[51.60s -> 53.70s]  will be critical in this new era.\n",
      "[54.34s -> 56.98s]  In other words, we need Stripe to ensure that\n",
      "[57.04s -> 63.04s]  the benefits of AI spread across the entire economy, not just to the magnificent 7.\n",
      "[63.04s -> 65.28s]  So that's at a high level.\n",
      "[65.28s -> 68.80s]  In terms of the specific role, there are a couple of things I love.\n",
      "[68.80s -> 75.04s]  First, this position focuses on internal customers in finance, accounting, and treasury.\n",
      "[75.04s -> 80.40s]  And I am sure some people may strongly prefer having external customers, more standard products.\n",
      "[80.40s -> 85.34s]  But you know what? Throughout my career, I've found that the kind of intimacy you can build with\n",
      "[85.34s -> 90.54s]  internal customers is very special. You get to really understand their needs and that\n",
      "[90.54s -> 97.18s]  can lead to very impactful and long-lasting solutions. At PNC, for example, I developed a custom\n",
      "[97.18s -> 103.34s]  CRM system for the trade finance team that they loved so much. They kept using it for 15 years.\n",
      "[103.34s -> 109.74s]  So having internal customers is actually a positive for me. Second, I think AI will drive most of the\n",
      "[109.74s -> 115.32s]  product innovation in the next 10 years. This is going to be true everywhere, but particularly\n",
      "[115.34s -> 118.94s]  in financial services, where data plays such a key role.\n",
      "[119.90s -> 124.98s]  I have seen early results of this at Amazon, where the team used machine learning to build a\n",
      "[124.98s -> 130.82s]  cash forecasting tool that blew the old tool out of the water, and ran in 30 minns instead of\n",
      "[130.82s -> 137.38s]  eight hours. That tool won the Adam Smith Award for Best Cash Flow Forecasting Solution in\n",
      "[137.38s -> 144.26s]  2023. You can check it out. And I personally envisioned machine learning tools to detect anomalies in the\n",
      "[144.26s -> 149.56s]  timing and the content of bank statements coming from banks. But this is just scratching\n",
      "[149.56s -> 155.62s]  the surface on the potential of ML and AI. I am so passionate about this possibilities that I quit my\n",
      "[155.62s -> 162.48s]  job last year to focus on studying AI. That passion, along with my decades of experience in financial\n",
      "[162.48s -> 168.26s]  services, including banking, payments, and treasury management, tells me I can add tons of value\n",
      "[168.26s -> 174.14s]  in this role. So when I saw this role combining AI innovation with internal financial\n",
      "[174.14s -> 178.90s]  systems at a company whose mission I believe in, it felt like a perfect fit.\n"
     ]
    }
   ],
   "source": [
    "# Transcribe using local faster whisper model\n",
    "model = \"local-faster-whisper\"\n",
    "model_size = \"distil-large-v3\"\n",
    "response = local_faster_whisper_transcribe(\n",
    "    file_path=file_path, \n",
    "    model_size=model_size,\n",
    "    device=\"cuda\",\n",
    "    )\n",
    "text:str = response[\"text\"]\n",
    "language:str = response[\"language\"]\n",
    "transcription:any = response[\"transcription\"]\n",
    "duration:float = response[\"inference_time\"]\n",
    "print(f\"duration = {duration:.2f} seconds\")\n",
    "print(f\"{text=}\")\n",
    "print(f\"{language=}\")\n",
    "print(f\"{transcription=}\")\n",
    "print(f\"transcription type: {type(transcription).__name__}\")\n",
    "index=model+\"-\"+model_size+\"-transcription\"\n",
    "runs[index] = text\n",
    "durations[index] = duration\n",
    "\n",
    "# print segments - local models only\n",
    "segments = transcription[\"segments\"]\n",
    "print(f\"segments type: {type(segments).__name__}\")\n",
    "print(\"segments:\")\n",
    "for segment in segments:\n",
    "    print(f\"[{segment[\"start\"]:.2f}s -> {segment[\"end\"]:.2f}s] {segment[\"text\"]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0d74703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU cache cleared.\n"
     ]
    }
   ],
   "source": [
    "clear_GPU_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "473727c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running faster whisper model locally. \n",
      "file_path='media/000-why-Stripe.mp3'\n",
      " model_size='deepdml/faster-whisper-large-v3-turbo-ct2'\n",
      " device='cuda'\n",
      " compute_type='float16'\n",
      " language=None\n",
      " prompt=None\n",
      "\n",
      "Detected language en with probability 1.0\n",
      "duration = 4.17 seconds\n",
      "text=\" Why Stripe? Well, the mission of increasing the GDP of the internet and the key role Stripe plays for small companies in particular really resonate with me, and here is why. The last several years have been all about big tech, right? Particularly the largest players, the Magnificent Seven. That's nice because I have some Nvidia shares, but in the long term, that kind of concentration of economic growth is not good for the country or the world. This is something Patrick and John Collison probably agree with because I saw them talking about that in a podcast. But I believe that we're entering a new era where AI will enable smaller companies and startups to compete more effectively and regain their key role in the economy. Stripe's role in providing these businesses with trust and access to enterprise-grade financial infrastructure will be critical in this new era. In other words, we need Stripe to ensure that the benefits of AI spread across the entire economy, not just to the Magnificent Seven. So that's at a high level. In terms of the specific role, there are a couple of things I love. First, this position focuses on internal customers in finance, accounting, and treasury. And I am sure some people may strongly prefer having external customers, more standard products. But you know what? Throughout my career, I've found that the kind of intimacy you can build with internal customers is very special. You get to really understand their needs, and that can lead to very impactful and long-lasting solutions. At PNC, for example, I developed a custom CRM system for the trade finance team that they loved so much. They kept using it for 15 years. So having internal customers is actually a positive for me. Second, I think AI will drive most of the product innovation in the next 10 years. This is going to be true everywhere, but particularly in financial services, where data plays such a key role. I have seen early results of this at Amazon, where the team used machine learning to build a cash forecasting tool that blew the old tool out of the water and ran in 30 mins instead of 8 hours. That tool won the Adam Smith Award for Best Cash Flow Forecasting Solution in 2023. You can check it out. And I personally envisioned machine learning tools to detect anomalies in the timing and the content of bank statements coming from banks. But this is just scratching the surface on the potential of ML and AI. I am so passionate about these possibilities that I quit my job last year to focus on studying AI. That passion, along with my decades of experience in financial services, including banking, payments, and treasury management, tells me I can add tons of value in this role. So when I saw this role combining AI innovation with internal financial systems at a company whose mission I believe in, it felt like a perfect fit.\"\n",
      "language='en'\n",
      "transcription={'segments': [{'start': 0.0, 'end': 6.7, 'text': ' Why Stripe? Well, the mission of increasing the GDP of the internet and the key role Stripe plays'}, {'start': 6.7, 'end': 13.06, 'text': ' for small companies in particular really resonate with me, and here is why. The last several years'}, {'start': 13.06, 'end': 18.18, 'text': ' have been all about big tech, right? Particularly the largest players, the Magnificent Seven.'}, {'start': 18.580000000000002, 'end': 23.38, 'text': \" That's nice because I have some Nvidia shares, but in the long term, that kind of concentration\"}, {'start': 23.38, 'end': 29.14, 'text': ' of economic growth is not good for the country or the world. This is something Patrick and John'}, {'start': 29.14, 'end': 34.76, 'text': ' Collison probably agree with because I saw them talking about that in a podcast. But I believe'}, {'start': 34.76, 'end': 40.94, 'text': \" that we're entering a new era where AI will enable smaller companies and startups to compete\"}, {'start': 40.94, 'end': 47.24, 'text': \" more effectively and regain their key role in the economy. Stripe's role in providing these\"}, {'start': 47.24, 'end': 53.18, 'text': ' businesses with trust and access to enterprise-grade financial infrastructure will be critical in this'}, {'start': 53.18, 'end': 59.120000000000005, 'text': ' new era. In other words, we need Stripe to ensure that the benefits of AI spread across the'}, {'start': 59.120000000000005, 'end': 64.12, 'text': \" entire economy, not just to the Magnificent Seven. So that's at a high level.\"}, {'start': 64.74000000000001, 'end': 69.88000000000001, 'text': ' In terms of the specific role, there are a couple of things I love. First, this position'}, {'start': 69.88000000000001, 'end': 76.14, 'text': ' focuses on internal customers in finance, accounting, and treasury. And I am sure some people may'}, {'start': 76.14, 'end': 79.74000000000001, 'text': ' strongly prefer having external customers, more standard products.'}, {'start': 79.74, 'end': 85.38, 'text': \" But you know what? Throughout my career, I've found that the kind of intimacy you can build with\"}, {'start': 85.38, 'end': 91.08, 'text': ' internal customers is very special. You get to really understand their needs, and that can lead to'}, {'start': 91.08, 'end': 98.38, 'text': ' very impactful and long-lasting solutions. At PNC, for example, I developed a custom CRM system for the'}, {'start': 98.38, 'end': 104.11999999999999, 'text': ' trade finance team that they loved so much. They kept using it for 15 years. So having internal'}, {'start': 104.12, 'end': 110.64, 'text': ' customers is actually a positive for me. Second, I think AI will drive most of the product innovation'}, {'start': 110.64, 'end': 116.72, 'text': ' in the next 10 years. This is going to be true everywhere, but particularly in financial services,'}, {'start': 117.04, 'end': 123.56, 'text': ' where data plays such a key role. I have seen early results of this at Amazon, where the team used'}, {'start': 123.56, 'end': 129.72, 'text': ' machine learning to build a cash forecasting tool that blew the old tool out of the water and ran in'}, {'start': 129.72, 'end': 136.38, 'text': ' 30 mins instead of 8 hours. That tool won the Adam Smith Award for Best Cash Flow Forecasting'}, {'start': 136.38, 'end': 142.28, 'text': ' Solution in 2023. You can check it out. And I personally envisioned machine learning tools'}, {'start': 142.28, 'end': 148.94, 'text': ' to detect anomalies in the timing and the content of bank statements coming from banks. But this is'}, {'start': 148.94, 'end': 154.84, 'text': ' just scratching the surface on the potential of ML and AI. I am so passionate about these possibilities'}, {'start': 154.84, 'end': 161.8, 'text': ' that I quit my job last year to focus on studying AI. That passion, along with my decades of experience'}, {'start': 161.8, 'end': 167.92000000000002, 'text': ' in financial services, including banking, payments, and treasury management, tells me I can add tons of'}, {'start': 167.92000000000002, 'end': 175.18, 'text': ' value in this role. So when I saw this role combining AI innovation with internal financial systems at a'}, {'start': 175.18, 'end': 178.9, 'text': ' company whose mission I believe in, it felt like a perfect fit.'}], 'info': TranscriptionInfo(language='en', language_probability=1.0, duration=179.112, duration_after_vad=179.112, all_language_probs=[('en', 1.0), ('es', 3.2961368560791016e-05), ('de', 2.282857894897461e-05), ('fr', 1.722574234008789e-05), ('ru', 1.6570091247558594e-05), ('pt', 1.3649463653564453e-05), ('ja', 1.3530254364013672e-05), ('it', 1.0311603546142578e-05), ('ko', 8.344650268554688e-06), ('zh', 6.020069122314453e-06), ('nl', 4.231929779052734e-06), ('id', 3.874301910400391e-06), ('tr', 3.4570693969726562e-06), ('sv', 3.2782554626464844e-06), ('pl', 2.7418136596679688e-06), ('vi', 2.2649765014648438e-06), ('tl', 2.2649765014648438e-06), ('ar', 1.6093254089355469e-06), ('fi', 1.0132789611816406e-06), ('no', 7.748603820800781e-07), ('ro', 7.152557373046875e-07), ('cs', 5.364418029785156e-07), ('hu', 3.5762786865234375e-07), ('uk', 2.980232238769531e-07), ('el', 2.980232238769531e-07), ('da', 2.980232238769531e-07), ('ca', 2.384185791015625e-07), ('ms', 2.384185791015625e-07), ('sk', 1.7881393432617188e-07), ('he', 1.1920928955078125e-07), ('et', 5.960464477539063e-08), ('az', 5.960464477539063e-08), ('ur', 5.960464477539063e-08), ('hr', 5.960464477539063e-08), ('bg', 5.960464477539063e-08), ('lt', 5.960464477539063e-08), ('fa', 5.960464477539063e-08), ('lv', 5.960464477539063e-08), ('sl', 5.960464477539063e-08), ('is', 5.960464477539063e-08), ('af', 5.960464477539063e-08), ('la', 0.0), ('mi', 0.0), ('ml', 0.0), ('cy', 0.0), ('te', 0.0), ('bn', 0.0), ('sr', 0.0), ('kn', 0.0), ('mk', 0.0), ('br', 0.0), ('eu', 0.0), ('hi', 0.0), ('hy', 0.0), ('ne', 0.0), ('mn', 0.0), ('bs', 0.0), ('kk', 0.0), ('sq', 0.0), ('sw', 0.0), ('gl', 0.0), ('mr', 0.0), ('pa', 0.0), ('si', 0.0), ('km', 0.0), ('sn', 0.0), ('yo', 0.0), ('so', 0.0), ('ta', 0.0), ('oc', 0.0), ('ka', 0.0), ('be', 0.0), ('tg', 0.0), ('sd', 0.0), ('gu', 0.0), ('am', 0.0), ('yi', 0.0), ('lo', 0.0), ('uz', 0.0), ('fo', 0.0), ('ht', 0.0), ('ps', 0.0), ('tk', 0.0), ('nn', 0.0), ('mt', 0.0), ('sa', 0.0), ('lb', 0.0), ('my', 0.0), ('bo', 0.0), ('th', 0.0), ('mg', 0.0), ('as', 0.0), ('tt', 0.0), ('haw', 0.0), ('ln', 0.0), ('ha', 0.0), ('ba', 0.0), ('jw', 0.0), ('su', 0.0), ('yue', 0.0)], transcription_options=TranscriptionOptions(beam_size=5, best_of=5, patience=1, length_penalty=1, repetition_penalty=1, no_repeat_ngram_size=0, log_prob_threshold=-1.0, no_speech_threshold=0.6, compression_ratio_threshold=2.4, condition_on_previous_text=True, prompt_reset_on_temperature=0.5, temperatures=[0.0, 0.2, 0.4, 0.6, 0.8, 1.0], initial_prompt=None, prefix=None, suppress_blank=True, suppress_tokens=[-1], without_timestamps=False, max_initial_timestamp=1.0, word_timestamps=False, prepend_punctuations='\"\\'âÂ¿([{-', append_punctuations='\"\\'.ã,ï¼!ï¼?ï¼:ï¼â)]}ã', max_new_tokens=None, clip_timestamps='0', hallucination_silence_threshold=None, hotwords=None), vad_options=None)}\n",
      "transcription type: dict\n",
      "segments type: list\n",
      "segments:\n",
      "[0.00s -> 6.70s]  Why Stripe? Well, the mission of increasing the GDP of the internet and the key role Stripe plays\n",
      "[6.70s -> 13.06s]  for small companies in particular really resonate with me, and here is why. The last several years\n",
      "[13.06s -> 18.18s]  have been all about big tech, right? Particularly the largest players, the Magnificent Seven.\n",
      "[18.58s -> 23.38s]  That's nice because I have some Nvidia shares, but in the long term, that kind of concentration\n",
      "[23.38s -> 29.14s]  of economic growth is not good for the country or the world. This is something Patrick and John\n",
      "[29.14s -> 34.76s]  Collison probably agree with because I saw them talking about that in a podcast. But I believe\n",
      "[34.76s -> 40.94s]  that we're entering a new era where AI will enable smaller companies and startups to compete\n",
      "[40.94s -> 47.24s]  more effectively and regain their key role in the economy. Stripe's role in providing these\n",
      "[47.24s -> 53.18s]  businesses with trust and access to enterprise-grade financial infrastructure will be critical in this\n",
      "[53.18s -> 59.12s]  new era. In other words, we need Stripe to ensure that the benefits of AI spread across the\n",
      "[59.12s -> 64.12s]  entire economy, not just to the Magnificent Seven. So that's at a high level.\n",
      "[64.74s -> 69.88s]  In terms of the specific role, there are a couple of things I love. First, this position\n",
      "[69.88s -> 76.14s]  focuses on internal customers in finance, accounting, and treasury. And I am sure some people may\n",
      "[76.14s -> 79.74s]  strongly prefer having external customers, more standard products.\n",
      "[79.74s -> 85.38s]  But you know what? Throughout my career, I've found that the kind of intimacy you can build with\n",
      "[85.38s -> 91.08s]  internal customers is very special. You get to really understand their needs, and that can lead to\n",
      "[91.08s -> 98.38s]  very impactful and long-lasting solutions. At PNC, for example, I developed a custom CRM system for the\n",
      "[98.38s -> 104.12s]  trade finance team that they loved so much. They kept using it for 15 years. So having internal\n",
      "[104.12s -> 110.64s]  customers is actually a positive for me. Second, I think AI will drive most of the product innovation\n",
      "[110.64s -> 116.72s]  in the next 10 years. This is going to be true everywhere, but particularly in financial services,\n",
      "[117.04s -> 123.56s]  where data plays such a key role. I have seen early results of this at Amazon, where the team used\n",
      "[123.56s -> 129.72s]  machine learning to build a cash forecasting tool that blew the old tool out of the water and ran in\n",
      "[129.72s -> 136.38s]  30 mins instead of 8 hours. That tool won the Adam Smith Award for Best Cash Flow Forecasting\n",
      "[136.38s -> 142.28s]  Solution in 2023. You can check it out. And I personally envisioned machine learning tools\n",
      "[142.28s -> 148.94s]  to detect anomalies in the timing and the content of bank statements coming from banks. But this is\n",
      "[148.94s -> 154.84s]  just scratching the surface on the potential of ML and AI. I am so passionate about these possibilities\n",
      "[154.84s -> 161.80s]  that I quit my job last year to focus on studying AI. That passion, along with my decades of experience\n",
      "[161.80s -> 167.92s]  in financial services, including banking, payments, and treasury management, tells me I can add tons of\n",
      "[167.92s -> 175.18s]  value in this role. So when I saw this role combining AI innovation with internal financial systems at a\n",
      "[175.18s -> 178.90s]  company whose mission I believe in, it felt like a perfect fit.\n"
     ]
    }
   ],
   "source": [
    "# Transcribe using local faster whisper model\n",
    "model = \"local-faster-whisper\"\n",
    "model_size = \"deepdml/faster-whisper-large-v3-turbo-ct2\"\n",
    "response = local_faster_whisper_transcribe(\n",
    "    file_path=file_path, \n",
    "    model_size=model_size,\n",
    "    device=\"cuda\",\n",
    "    )\n",
    "text:str = response[\"text\"]\n",
    "language:str = response[\"language\"]\n",
    "transcription:any = response[\"transcription\"]\n",
    "duration:float = response[\"inference_time\"]\n",
    "print(f\"duration = {duration:.2f} seconds\")\n",
    "print(f\"{text=}\")\n",
    "print(f\"{language=}\")\n",
    "print(f\"{transcription=}\")\n",
    "print(f\"transcription type: {type(transcription).__name__}\")\n",
    "index=model+\"-\"+model_size+\"-transcription\"\n",
    "runs[index] = text\n",
    "durations[index] = duration\n",
    "\n",
    "# print segments - local models only\n",
    "segments = transcription[\"segments\"]\n",
    "print(f\"segments type: {type(segments).__name__}\")\n",
    "print(\"segments:\")\n",
    "for segment in segments:\n",
    "    print(f\"[{segment[\"start\"]:.2f}s -> {segment[\"end\"]:.2f}s] {segment[\"text\"]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ca4738",
   "metadata": {},
   "source": [
    "* **Faster whisper Output** \n",
    "\n",
    "* -> Tuple[Iterable[Segment], TranscriptionInfo]:\n",
    "\n",
    "* class Segment(NamedTuple):\n",
    "    * id: int\n",
    "    * seek: int\n",
    "    * start: float\n",
    "    * end: float\n",
    "    * text: str\n",
    "    * tokens: List[int]\n",
    "    * temperature: float\n",
    "    * avg_logprob: float\n",
    "    * compression_ratio: float\n",
    "    * no_speech_prob: float\n",
    "    * words: Optional[List[Word]]\n",
    "\n",
    "* class TranscriptionInfo(NamedTuple):\n",
    "    * language: str\n",
    "    * language_probability: float\n",
    "    * duration: float\n",
    "    * duration_after_vad: float\n",
    "    * all_language_probs: Optional[List[Tuple[str, float]]]\n",
    "    * transcription_options: TranscriptionOptions\n",
    "    * vad_options: VadOptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a27cf43",
   "metadata": {},
   "source": [
    "# Language detection using local whisper\n",
    "\n",
    "Detect language with local open source whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fca6d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect language using local whisper model\n",
    "result = local_detect_language(file_path)\n",
    "language = result[\"language\"]\n",
    "probability = result[\"probability\"]\n",
    "all_probabilities = result[\"all_probabilities\"]\n",
    "print(f\"Detected language: {language} with probability {probability:.2f}\")\n",
    "print(\"All probabilities:\")\n",
    "for lang, prob in all_probabilities.items():\n",
    "    print(f\"{lang}: {prob:.2f}\", end=\" \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be721b4",
   "metadata": {},
   "source": [
    "Visualize language probability distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50564392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create probability distribution chart\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Sort probabilities in descending order\n",
    "sorted_probs = sorted(all_probabilities.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Take top 10 languages for better visualization\n",
    "top_n = min(10, len(sorted_probs))\n",
    "languages = [item[0] for item in sorted_probs[:top_n]]\n",
    "probabilities = [item[1] for item in sorted_probs[:top_n]]\n",
    "\n",
    "# Create the chart\n",
    "plt.figure(figsize=(12, 6))\n",
    "bars = plt.bar(languages, probabilities, color='skyblue', edgecolor='navy', alpha=0.7)\n",
    "\n",
    "# Highlight the detected language\n",
    "detected_idx = languages.index(language) if language in languages else -1\n",
    "if detected_idx >= 0:\n",
    "    bars[detected_idx].set_color('orange')\n",
    "    bars[detected_idx].set_edgecolor('red')\n",
    "\n",
    "plt.title(f'Language Detection Probability Distribution\\nDetected: {language} ({probability:.3f})', \n",
    "          fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Language Code', fontsize=12)\n",
    "plt.ylabel('Probability', fontsize=12)\n",
    "plt.ylim(0, max(probabilities) * 1.1)\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, (lang, prob) in enumerate(zip(languages, probabilities)):\n",
    "    plt.text(i, prob + max(probabilities) * 0.01, f'{prob:.3f}', \n",
    "             ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Also create a pie chart for top 5 languages\n",
    "top_5_langs = languages[:5]\n",
    "top_5_probs = probabilities[:5]\n",
    "other_prob = sum(probabilities[5:]) if len(probabilities) > 5 else 0\n",
    "\n",
    "if other_prob > 0:\n",
    "    top_5_langs.append('Others')\n",
    "    top_5_probs.append(other_prob)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "colors = ['orange' if lang == language else 'lightblue' for lang in top_5_langs]\n",
    "if 'Others' in top_5_langs:\n",
    "    colors[-1] = 'lightgray'\n",
    "\n",
    "plt.pie(top_5_probs, labels=top_5_langs, autopct='%1.1f%%', \n",
    "        colors=colors, explode=[0.1 if lang == language else 0 for lang in top_5_langs])\n",
    "plt.title(f'Top Languages Distribution\\nDetected: {language}', fontsize=14, fontweight='bold')\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65051413",
   "metadata": {},
   "source": [
    "# Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54618031",
   "metadata": {},
   "outputs": [],
   "source": [
    "from carlos_tools_misc import function_timer\n",
    "from carlos_tools_audio import OpenAI_translate, local_whisper_translate, local_faster_whisper_translate\n",
    "from typing import Literal\n",
    "\n",
    "# file_path = \"Audio.wav\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b2bfbc",
   "metadata": {},
   "source": [
    "### Translation using OpenAI Whisper\n",
    "\n",
    "Whisper treats transcription and translation as prompted decoding tasks, both starting from the same audio encoder output.\n",
    "\n",
    "**Shared architecture:**\n",
    "\n",
    "* **Input**: 30-second audio segment â encoded into latent representations.\n",
    "\n",
    "* **Output**: A sequence of text tokens â either in the original language (transcription) or in English (translation).\n",
    "\n",
    "The only thing that changes is the task token in the decoder prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16f844a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translate using OpenAI's Whisper-1 model - other OpenAI models do not support translation\n",
    "# verbose_json response format --> translation output is TranslationVerbose object, which includes segments, which is a list of openai.types.audio.transcription_segment.TranscriptionSegment objects\n",
    "model = \"whisper-1\"\n",
    "response_format=\"verbose_json\"\n",
    "response = OpenAI_translate(\n",
    "    file_path=file_path, \n",
    "    model=model,\n",
    "    response_format=response_format,\n",
    "    language=\"es\",  \n",
    "    )\n",
    "text:str = response[\"text\"]\n",
    "language:str = response[\"language\"]\n",
    "translation:any = response[\"translation\"]\n",
    "duration:float = response[\"inference_time\"]\n",
    "print(f\"duration = {duration:.2f} seconds\")\n",
    "print(f\"{text=}\")\n",
    "print(f\"{language=}\")\n",
    "print(f\"{translation=}\")\n",
    "print(f\"translation type: {type(translation).__name__}\")\n",
    "index=model+\"-translation-\"+response_format\n",
    "runs[index] = text\n",
    "durations[index] = duration\n",
    "\n",
    "# print segments - only available in verbose_json response format\n",
    "if hasattr(translation, 'segments') and translation.segments:\n",
    "    segments = translation.segments\n",
    "    for segment in segments:\n",
    "        print(f\"[{segment.start:.2f}s -> {segment.end:.2f}s] {segment.text}\")\n",
    "else:\n",
    "    print(\"No segments available in translation object\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7102a361",
   "metadata": {},
   "source": [
    "**OpenAI whisper Output** The format of the ouput depends on response_format\n",
    "\n",
    "if response_format= \"text\", \"srt\", \"vtt\" --> str\n",
    "\n",
    "\n",
    "if response_format=\"json\", None --> Translation object:\n",
    "* text: str\n",
    "\n",
    "if response_format=\"verbose_json\" --> TranslationVerbose object\n",
    "\n",
    "* duration: str - The duration of the input audio\n",
    "* language: str - The language of the output translation (always 'english')\n",
    "* text: str - The translated text.\n",
    "* segments: List[TranscriptionSegment] - Segments of the translated text and their corresponding details\n",
    "\n",
    "## Translation using open-source options\n",
    "### Translation using local whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bd27bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_GPU_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bae43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translation using local whisper model\n",
    "model = \"local-whisper\"\n",
    "model_size = \"large-v3\"\n",
    "response = local_whisper_translate(\n",
    "    file_path=file_path, \n",
    "    model_size=model_size,\n",
    "    device=\"cuda\",\n",
    "    verbose=False, # Set to True for segments printed as they are processed\n",
    "    prompt=\"\",\n",
    "    language=None,  # if language is None, it will be detected automatically\n",
    "    )\n",
    "text:str = response[\"text\"]\n",
    "language:str = response[\"language\"]\n",
    "translation:any = response[\"translation\"]\n",
    "duration:float = response[\"inference_time\"]\n",
    "print(f\"duration = {duration:.2f} seconds\")\n",
    "print(f\"{text=}\")\n",
    "print(f\"{language=}\")\n",
    "print(f\"{translation=}\")\n",
    "print(f\"translation type: {type(translation).__name__}\")\n",
    "index=model+\"-\"+model_size+\"-translation\"\n",
    "runs[index] = text\n",
    "durations[index] = duration\n",
    "\n",
    "# print segments - local models only\n",
    "segments = translation[\"segments\"]\n",
    "print(f\"segments type: {type(segments).__name__}\")\n",
    "print(\"segments:\")\n",
    "for segment in segments:\n",
    "    print(f\"[{segment[\"start\"]:.2f}s -> {segment[\"end\"]:.2f}s] {segment[\"text\"]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9536607",
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_GPU_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c314f0",
   "metadata": {},
   "source": [
    "whisper-large-v3-turbo a.k.a. \"turbo\" was not trained for translation and does not support it well. We use medium here, which works fine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f43f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translation using local whisper model\n",
    "model = \"local-whisper\"\n",
    "model_size = \"medium\"\n",
    "response = local_whisper_translate(\n",
    "    file_path=file_path, \n",
    "    model_size=model_size,\n",
    "    device=\"cuda\",\n",
    "    verbose=False, # Set to True for segments printed as they are processed\n",
    "    prompt=\"\",\n",
    "    language=\"es\",  # if language provided, it will not be detected automatically\n",
    "    )\n",
    "text:str = response[\"text\"]\n",
    "language:str = response[\"language\"]\n",
    "translation:any = response[\"translation\"]\n",
    "duration:float = response[\"inference_time\"]\n",
    "print(f\"duration = {duration:.2f} seconds\")\n",
    "print(f\"{text=}\")\n",
    "print(f\"{language=}\")\n",
    "print(f\"{translation=}\")\n",
    "print(f\"translation type: {type(translation).__name__}\")\n",
    "index=model+\"-\"+model_size+\"-translation\"\n",
    "runs[index] = text\n",
    "durations[index] = duration\n",
    "\n",
    "# print segments - local models only\n",
    "segments = translation[\"segments\"]\n",
    "print(f\"segments type: {type(segments).__name__}\")\n",
    "print(\"segments:\")\n",
    "for segment in segments:\n",
    "    print(f\"[{segment[\"start\"]:.2f}s -> {segment[\"end\"]:.2f}s] {segment[\"text\"]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990b9a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_GPU_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d7dff8",
   "metadata": {},
   "source": [
    "### Translation using Faster Whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e062ad12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Translation using local whisper model\n",
    "# model = \"local-faster-whisper\"\n",
    "# model_size = \"large-v3\"\n",
    "# response = local_faster_whisper_translate(\n",
    "#     file_path=file_path, \n",
    "#     model_size=model_size,\n",
    "#     device=\"cuda\",\n",
    "#     language=\"es\",\n",
    "#     prompt=\"\",\n",
    "#     )\n",
    "# text:str = response[\"text\"]\n",
    "# language:str = response[\"language\"]\n",
    "# translation:any = response[\"translation\"]\n",
    "# duration:float = response[\"inference_time\"]\n",
    "# print(f\"duration = {duration:.2f} seconds\")\n",
    "# print(f\"{text=}\")\n",
    "# print(f\"{language=}\")\n",
    "# print(f\"{translation=}\")\n",
    "# print(f\"translation type: {type(translation).__name__}\")\n",
    "# index=model+\"-\"+model_size+\"-translation\"\n",
    "# runs[index] = text\n",
    "# durations[index] = duration\n",
    "\n",
    "# # print segments - local models only\n",
    "# segments = translation[\"segments\"]\n",
    "# print(f\"segments type: {type(segments).__name__}\")\n",
    "# print(\"segments:\")\n",
    "# for segment in segments:\n",
    "#     print(f\"[{segment[\"start\"]:.2f}s -> {segment[\"end\"]:.2f}s] {segment[\"text\"]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c30ebe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output from local-faster-whisper-distil-large-v3-transcription:\n",
      "   Why Stripe? Well, the mission of increasing the GDP of the Internet and the key role Stripe plays for small companies in particular really resonate with me, and here is why. The last several years have been all about big tech, right? Particularly the largest players, the Magnificent Seven. That's nice because I have some Nvidia shares, but in the long term, that kind of concentration of economic growth is not good for the country or the world. This is something Patrick and John Collison probably agree with because I saw them talking about that in a podcast. But I believe that we're entering a new era where AI will enable smaller companies and startups to compete more effectively and regain their key role in the economy. Stripe's role in providing these businesses with trust and access to enterprise-grade financial infrastructure will be critical in this new era. In other words, we need Stripe to ensure that the benefits of AI spread across the entire economy, not just to the magnificent 7. So that's at a high level. In terms of the specific role, there are a couple of things I love. First, this position focuses on internal customers in finance, accounting, and treasury. And I am sure some people may strongly prefer having external customers, more standard products. But you know what? Throughout my career, I've found that the kind of intimacy you can build with internal customers is very special. You get to really understand their needs and that can lead to very impactful and long-lasting solutions. At PNC, for example, I developed a custom CRM system for the trade finance team that they loved so much. They kept using it for 15 years. So having internal customers is actually a positive for me. Second, I think AI will drive most of the product innovation in the next 10 years. This is going to be true everywhere, but particularly in financial services, where data plays such a key role. I have seen early results of this at Amazon, where the team used machine learning to build a cash forecasting tool that blew the old tool out of the water, and ran in 30 minns instead of eight hours. That tool won the Adam Smith Award for Best Cash Flow Forecasting Solution in 2023. You can check it out. And I personally envisioned machine learning tools to detect anomalies in the timing and the content of bank statements coming from banks. But this is just scratching the surface on the potential of ML and AI. I am so passionate about this possibilities that I quit my job last year to focus on studying AI. That passion, along with my decades of experience in financial services, including banking, payments, and treasury management, tells me I can add tons of value in this role. So when I saw this role combining AI innovation with internal financial systems at a company whose mission I believe in, it felt like a perfect fit.\n",
      "  Length: 2853 characters\n",
      "  Duration: 3.92 seconds\n",
      "----------------------------------------\n",
      "Output from local-faster-whisper-deepdml/faster-whisper-large-v3-turbo-ct2-transcription:\n",
      "   Why Stripe? Well, the mission of increasing the GDP of the internet and the key role Stripe plays for small companies in particular really resonate with me, and here is why. The last several years have been all about big tech, right? Particularly the largest players, the Magnificent Seven. That's nice because I have some Nvidia shares, but in the long term, that kind of concentration of economic growth is not good for the country or the world. This is something Patrick and John Collison probably agree with because I saw them talking about that in a podcast. But I believe that we're entering a new era where AI will enable smaller companies and startups to compete more effectively and regain their key role in the economy. Stripe's role in providing these businesses with trust and access to enterprise-grade financial infrastructure will be critical in this new era. In other words, we need Stripe to ensure that the benefits of AI spread across the entire economy, not just to the Magnificent Seven. So that's at a high level. In terms of the specific role, there are a couple of things I love. First, this position focuses on internal customers in finance, accounting, and treasury. And I am sure some people may strongly prefer having external customers, more standard products. But you know what? Throughout my career, I've found that the kind of intimacy you can build with internal customers is very special. You get to really understand their needs, and that can lead to very impactful and long-lasting solutions. At PNC, for example, I developed a custom CRM system for the trade finance team that they loved so much. They kept using it for 15 years. So having internal customers is actually a positive for me. Second, I think AI will drive most of the product innovation in the next 10 years. This is going to be true everywhere, but particularly in financial services, where data plays such a key role. I have seen early results of this at Amazon, where the team used machine learning to build a cash forecasting tool that blew the old tool out of the water and ran in 30 mins instead of 8 hours. That tool won the Adam Smith Award for Best Cash Flow Forecasting Solution in 2023. You can check it out. And I personally envisioned machine learning tools to detect anomalies in the timing and the content of bank statements coming from banks. But this is just scratching the surface on the potential of ML and AI. I am so passionate about these possibilities that I quit my job last year to focus on studying AI. That passion, along with my decades of experience in financial services, including banking, payments, and treasury management, tells me I can add tons of value in this role. So when I saw this role combining AI innovation with internal financial systems at a company whose mission I believe in, it felt like a perfect fit.\n",
      "  Length: 2853 characters\n",
      "  Duration: 4.17 seconds\n",
      "----------------------------------------\n",
      "Output from local-whisper-large-v3-transcription:\n",
      "   Why Stripe? Well, the mission of increasing the GDP of the internet and the key role Stripe plays for small companies in particular really resonate with me. And here is why. The last several years have been all about big tech, right? Particularly the largest players, the Magnificent Seven. That's nice because I have some Nvidia shares. But in the long term, that kind of concentration of economic growth is not good for the country or the world. This is something Patrick and John Collison probably agree with because I saw them talking about that in a podcast. But I believe that we're entering a new era where AI will enable smaller companies and startups to compete more effectively and regain their key role in the economy. Stripe's role in providing these businesses with trust and access to enterprise-grade financial infrastructure will be critical in this new era. In other words, we need Stripe to ensure that the benefits of AI spread across the entire world. So that's at a high level. In terms of the specific role, there are a couple of things I love. First, this position focuses on internal customers in finance, accounting, and treasury. And I am sure some people may strongly prefer having external customers, more standard products. But you know what? Throughout my career, I've found that the kind of intimacy you can build with internal customers is very special. You get to really understand the value of the product. And that can lead to very impactful and long-lasting solutions. At PNC, for example, I developed a custom CRM system for the trade finance team that they loved so much. They kept using it for 15 years. So having internal customers is actually a positive for me. Second, I think AI will drive most of the product innovation in the next 10 years. This is going to be true everywhere, but particularly in financial services, where data plays such a key role. I have seen early results of this at Amazon, where the team used machine learning to build a cash forecasting tool that blew the old tool out of the water and ran in 30 mins instead of 8 hours. That tool won the Adam Smith Award for Best Cash Flow Forecasting Solution in 2023. You can check it out. And I personally envisioned machine learning tools to detect anomalies in the timing and the content of bank statements coming from banks. But this is just a matter of time. This is just scratching the surface on the potential of ML and AI. I am so passionate about these possibilities that I quit my job last year to focus on studying AI. That passion, along with my decades of experience in financial services, including banking, payments, and treasury management, tells me I can add tons of value in this role. So when I saw this role combining AI innovation with internal financial systems at a company whose mission I believe in, it felt like a perfect fit. I could not believe an ML partner was there, as if maybe more than 3% of ML community was aware of this fact. It was world-famous back then. And I certainly think might become the most Howard Gould- herzlich honored campus junior assistant. I think I have experienced a lot better! I didÃ©r! I was Response! Nothing. I'm Ã¥ierung! I'm Ã¥ring!\n",
      "  Length: 3200 characters\n",
      "  Duration: 70.09 seconds\n",
      "----------------------------------------\n",
      "Output from local-whisper-turbo-transcription:\n",
      "   why stripe well the mission of increasing the gdp of the internet and the key role stripe plays for small companies in particular really resonate with me and here is why the last several years have been all about big tech right particularly the largest players the magnificent seven that's nice because i have some nvidia shares but in the long term that kind of concentration of economic growth is not good for the country or the world this is something patrick and john collison probably agree with because i saw them talking about that in a podcast but i believe that we're entering a new era where ai will enable smaller companies and start-ups to compete more effectively and regain their key role in the economy stripe's role in providing these businesses with trust and access to enterprise grade financial infrastructure will be critical in this new era in other words we need stripe to ensure that the benefits of ai spread across the entire economy not just to the magnificent seven so that's at a high level in terms of the specific role there are a couple of things i love first this position focuses on internal customers in finance accounting and treasury and i am sure some people may strongly prefer having external customers more standard products but you know what throughout my career i've found that the kind of intimacy you can build with internal customers is very special you get to really understand their needs and that can lead to very impactful and long-lasting solutions at pnc for example i developed a custom crm system for the trade finance team that they loved so much they kept using it for 15 years so having internal customers is actually a positive for me second i think ai will drive most of the product innovation in the next 10 years this is going to be true everywhere but particularly in financial services where data plays such a key role i have seen early results of this at amazon where the team used machine learning to build a cash forecasting tool that blew the old tool out of the water and ran in 30 mins instead of eight hours that tool won the adam smith award for best cash flow forecasting solution in 2023 you can check it out and i personally envisioned machine learning tools to detect anomalies in the timing and the content of bank statements coming from banks but this is just scratching the surface on the potential of ml and ai i am so passionate about this possibilities that i quit my job last year to focus on studying ai that passion along with my decades of experience in financial services including banking payments and treasury management tells me i can add tons of value in this role so when i saw this role combining ai innovation with internal financial systems at a company whose mission i believe in it felt like a perfect fit\n",
      "  Length: 2801 characters\n",
      "  Duration: 9.16 seconds\n",
      "----------------------------------------\n",
      "\n",
      "ð CHARACTER-LEVEL COMPARISONS:\n",
      "============================================================\n",
      "\n",
      "ð local-faster-whisper-distil-large-v3-transcription vs local-faster-whisper-deepdml/faster-whisper-large-v3-turbo-ct2-transcription:--Similarity: 98.7%\n",
      "------------------------------------------------------------\n",
      "\n",
      "ð local-faster-whisper-distil-large-v3-transcription vs local-whisper-large-v3-transcription:--Similarity: 91.7%\n",
      "------------------------------------------------------------\n",
      "\n",
      "ð local-faster-whisper-distil-large-v3-transcription vs local-whisper-turbo-transcription:--Similarity: 59.7%\n",
      "------------------------------------------------------------\n",
      "\n",
      "ð local-faster-whisper-deepdml/faster-whisper-large-v3-turbo-ct2-transcription vs local-whisper-large-v3-transcription:--Similarity: 92.3%\n",
      "------------------------------------------------------------\n",
      "\n",
      "ð local-faster-whisper-deepdml/faster-whisper-large-v3-turbo-ct2-transcription vs local-whisper-turbo-transcription:--Similarity: 62.7%\n",
      "------------------------------------------------------------\n",
      "\n",
      "ð local-whisper-large-v3-transcription vs local-whisper-turbo-transcription:--Similarity: 50.7%\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def compare_transcriptions_char_diff(runs):\n",
    "    \"\"\"\n",
    "    Character-by-character comparison for single-line transcriptions\n",
    "    \"\"\"\n",
    "    import difflib\n",
    "    from itertools import combinations\n",
    "    \n",
    "    # Show all transcriptions first\n",
    "    for model, output in runs.items():\n",
    "        print(f\"Output from {model}:\")\n",
    "        print(f\"  {output}\")\n",
    "        print(f\"  Length: {len(output)} characters\")\n",
    "        print(f\"  Duration: {durations[model]:.2f} seconds\")\n",
    "        print(\"-\" * 40)\n",
    "    \n",
    "    # Show character-level differences\n",
    "    models = list(runs.keys())\n",
    "    print(f\"\\nð CHARACTER-LEVEL COMPARISONS:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for model1, model2 in combinations(models, 2):\n",
    "        print(f\"\\nð {model1} vs {model2}:\",end=\"--\")\n",
    "        \n",
    "        text1 = runs[model1]\n",
    "        text2 = runs[model2]\n",
    "        \n",
    "        # Calculate similarity\n",
    "        similarity = difflib.SequenceMatcher(None, text1, text2).ratio() * 100\n",
    "        print(f\"Similarity: {similarity:.1f}%\")\n",
    "        \n",
    "        # if similarity < 100:\n",
    "        #     # Show character-level differences\n",
    "        #     matcher = difflib.SequenceMatcher(None, text1, text2)\n",
    "            \n",
    "        #     print(\"Differences:\")\n",
    "        #     for tag, i1, i2, j1, j2 in matcher.get_opcodes():\n",
    "        #         if tag == 'replace':\n",
    "        #             print(f\"  REPLACE pos {i1}-{i2}: '{text1[i1:i2]}' â '{text2[j1:j2]}'\")\n",
    "        #         elif tag == 'delete':\n",
    "        #             print(f\"  DELETE  pos {i1}-{i2}: '{text1[i1:i2]}'\")\n",
    "        #         elif tag == 'insert':\n",
    "        #             print(f\"  INSERT  pos {j1}-{j2}: '{text2[j1:j2]}'\")\n",
    "        # else:\n",
    "        #     print(\"â Identical!\")\n",
    "        \n",
    "        print(\"-\" * 60)\n",
    "\n",
    "compare_transcriptions_char_diff(runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96c41bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Model  \\\n",
      "0  local-faster-whisper-distil-large-v3-transcrip...   \n",
      "1  local-faster-whisper-deepdml/faster-whisper-la...   \n",
      "2               local-whisper-large-v3-transcription   \n",
      "3                  local-whisper-turbo-transcription   \n",
      "\n",
      "                                              Output  Duration (s)  \n",
      "0   Why Stripe? Well, the mission of increasing t...      3.924846  \n",
      "1   Why Stripe? Well, the mission of increasing t...      4.174637  \n",
      "2   Why Stripe? Well, the mission of increasing t...     70.088029  \n",
      "3   why stripe well the mission of increasing the...      9.164318  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    \"Model\": list(runs.keys()),\n",
    "    \"Output\": list(runs.values()),\n",
    "    \"Duration (s)\": [durations[model] for model in runs.keys()]\n",
    "})\n",
    "\n",
    "# Display the table\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07489030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Output</th>\n",
       "      <th>Duration (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>local-faster-whisper-distil-large-v3-transcrip...</td>\n",
       "      <td>Why Stripe? Well, the mission of increasing t...</td>\n",
       "      <td>3.924846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>local-faster-whisper-deepdml/faster-whisper-la...</td>\n",
       "      <td>Why Stripe? Well, the mission of increasing t...</td>\n",
       "      <td>4.174637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>local-whisper-large-v3-transcription</td>\n",
       "      <td>Why Stripe? Well, the mission of increasing t...</td>\n",
       "      <td>70.088029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>local-whisper-turbo-transcription</td>\n",
       "      <td>why stripe well the mission of increasing the...</td>\n",
       "      <td>9.164318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Model  \\\n",
       "0  local-faster-whisper-distil-large-v3-transcrip...   \n",
       "1  local-faster-whisper-deepdml/faster-whisper-la...   \n",
       "2               local-whisper-large-v3-transcription   \n",
       "3                  local-whisper-turbo-transcription   \n",
       "\n",
       "                                              Output  Duration (s)  \n",
       "0   Why Stripe? Well, the mission of increasing t...      3.924846  \n",
       "1   Why Stripe? Well, the mission of increasing t...      4.174637  \n",
       "2   Why Stripe? Well, the mission of increasing t...     70.088029  \n",
       "3   why stripe well the mission of increasing the...      9.164318  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f637f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
